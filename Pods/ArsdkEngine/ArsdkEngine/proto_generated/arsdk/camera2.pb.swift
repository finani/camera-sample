// DO NOT EDIT.
// swift-format-ignore-file
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: arsdk/camera2.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

import Foundation
import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

enum Arsdk_Camera_AudioRecordingMode: SwiftProtobuf.Enum {
  typealias RawValue = Int

  /// TODO: Replace documentation example 
  case mute // = 0
  case drone // = 1
  case UNRECOGNIZED(Int)

  init() {
    self = .mute
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .mute
    case 1: self = .drone
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .mute: return 0
    case .drone: return 1
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_AudioRecordingMode: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_AudioRecordingMode] = [
    .mute,
    .drone,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_AutoRecordMode: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case disabled // = 0
  case flight // = 1
  case UNRECOGNIZED(Int)

  init() {
    self = .disabled
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .disabled
    case 1: self = .flight
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .disabled: return 0
    case .flight: return 1
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_AutoRecordMode: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_AutoRecordMode] = [
    .disabled,
    .flight,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_BracketingPreset: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case bracketingPreset1Ev // = 0
  case bracketingPreset2Ev // = 1
  case bracketingPreset3Ev // = 2
  case bracketingPreset1Ev2Ev // = 3
  case bracketingPreset1Ev3Ev // = 4
  case bracketingPreset2Ev3Ev // = 5
  case bracketingPreset1Ev2Ev3Ev // = 6
  case UNRECOGNIZED(Int)

  init() {
    self = .bracketingPreset1Ev
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .bracketingPreset1Ev
    case 1: self = .bracketingPreset2Ev
    case 2: self = .bracketingPreset3Ev
    case 3: self = .bracketingPreset1Ev2Ev
    case 4: self = .bracketingPreset1Ev3Ev
    case 5: self = .bracketingPreset2Ev3Ev
    case 6: self = .bracketingPreset1Ev2Ev3Ev
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .bracketingPreset1Ev: return 0
    case .bracketingPreset2Ev: return 1
    case .bracketingPreset3Ev: return 2
    case .bracketingPreset1Ev2Ev: return 3
    case .bracketingPreset1Ev3Ev: return 4
    case .bracketingPreset2Ev3Ev: return 5
    case .bracketingPreset1Ev2Ev3Ev: return 6
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_BracketingPreset: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_BracketingPreset] = [
    .bracketingPreset1Ev,
    .bracketingPreset2Ev,
    .bracketingPreset3Ev,
    .bracketingPreset1Ev2Ev,
    .bracketingPreset1Ev3Ev,
    .bracketingPreset2Ev3Ev,
    .bracketingPreset1Ev2Ev3Ev,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_BurstValue: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case burstValue14Over4S // = 0
  case burstValue14Over2S // = 1
  case burstValue14Over1S // = 2
  case burstValue10Over4S // = 3
  case burstValue10Over2S // = 4
  case burstValue10Over1S // = 5
  case burstValue4Over4S // = 6
  case burstValue4Over2S // = 7
  case burstValue4Over1S // = 8
  case UNRECOGNIZED(Int)

  init() {
    self = .burstValue14Over4S
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .burstValue14Over4S
    case 1: self = .burstValue14Over2S
    case 2: self = .burstValue14Over1S
    case 3: self = .burstValue10Over4S
    case 4: self = .burstValue10Over2S
    case 5: self = .burstValue10Over1S
    case 6: self = .burstValue4Over4S
    case 7: self = .burstValue4Over2S
    case 8: self = .burstValue4Over1S
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .burstValue14Over4S: return 0
    case .burstValue14Over2S: return 1
    case .burstValue14Over1S: return 2
    case .burstValue10Over4S: return 3
    case .burstValue10Over2S: return 4
    case .burstValue10Over1S: return 5
    case .burstValue4Over4S: return 6
    case .burstValue4Over2S: return 7
    case .burstValue4Over1S: return 8
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_BurstValue: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_BurstValue] = [
    .burstValue14Over4S,
    .burstValue14Over2S,
    .burstValue14Over1S,
    .burstValue10Over4S,
    .burstValue10Over2S,
    .burstValue10Over1S,
    .burstValue4Over4S,
    .burstValue4Over2S,
    .burstValue4Over1S,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_CameraMode: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case photo // = 0
  case recording // = 1
  case UNRECOGNIZED(Int)

  init() {
    self = .photo
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .photo
    case 1: self = .recording
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .photo: return 0
    case .recording: return 1
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_CameraMode: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_CameraMode] = [
    .photo,
    .recording,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_CameraModel: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case main // = 0
  case UNRECOGNIZED(Int)

  init() {
    self = .main
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .main
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .main: return 0
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_CameraModel: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_CameraModel] = [
    .main,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_DigitalSignature: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case none // = 0
  case drone // = 1
  case UNRECOGNIZED(Int)

  init() {
    self = .none
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .none
    case 1: self = .drone
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .none: return 0
    case .drone: return 1
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_DigitalSignature: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_DigitalSignature] = [
    .none,
    .drone,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_DynamicRange: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case standard // = 0
  case hdr8 // = 1
  case hdr10 // = 2
  case UNRECOGNIZED(Int)

  init() {
    self = .standard
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .standard
    case 1: self = .hdr8
    case 2: self = .hdr10
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .standard: return 0
    case .hdr8: return 1
    case .hdr10: return 2
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_DynamicRange: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_DynamicRange] = [
    .standard,
    .hdr8,
    .hdr10,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_EvCompensation: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case minus300 // = 0
  case minus267 // = 1
  case minus233 // = 2
  case minus200 // = 3
  case minus167 // = 4
  case minus133 // = 5
  case minus100 // = 6
  case minus067 // = 7
  case minus033 // = 8
  case evCompensation000 // = 9
  case evCompensation033 // = 10
  case evCompensation067 // = 11
  case evCompensation100 // = 12
  case evCompensation133 // = 13
  case evCompensation167 // = 14
  case evCompensation200 // = 15
  case evCompensation233 // = 16
  case evCompensation267 // = 17
  case evCompensation300 // = 18
  case UNRECOGNIZED(Int)

  init() {
    self = .minus300
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .minus300
    case 1: self = .minus267
    case 2: self = .minus233
    case 3: self = .minus200
    case 4: self = .minus167
    case 5: self = .minus133
    case 6: self = .minus100
    case 7: self = .minus067
    case 8: self = .minus033
    case 9: self = .evCompensation000
    case 10: self = .evCompensation033
    case 11: self = .evCompensation067
    case 12: self = .evCompensation100
    case 13: self = .evCompensation133
    case 14: self = .evCompensation167
    case 15: self = .evCompensation200
    case 16: self = .evCompensation233
    case 17: self = .evCompensation267
    case 18: self = .evCompensation300
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .minus300: return 0
    case .minus267: return 1
    case .minus233: return 2
    case .minus200: return 3
    case .minus167: return 4
    case .minus133: return 5
    case .minus100: return 6
    case .minus067: return 7
    case .minus033: return 8
    case .evCompensation000: return 9
    case .evCompensation033: return 10
    case .evCompensation067: return 11
    case .evCompensation100: return 12
    case .evCompensation133: return 13
    case .evCompensation167: return 14
    case .evCompensation200: return 15
    case .evCompensation233: return 16
    case .evCompensation267: return 17
    case .evCompensation300: return 18
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_EvCompensation: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_EvCompensation] = [
    .minus300,
    .minus267,
    .minus233,
    .minus200,
    .minus167,
    .minus133,
    .minus100,
    .minus067,
    .minus033,
    .evCompensation000,
    .evCompensation033,
    .evCompensation067,
    .evCompensation100,
    .evCompensation133,
    .evCompensation167,
    .evCompensation200,
    .evCompensation233,
    .evCompensation267,
    .evCompensation300,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_ExposureLockMode: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case unlocked // = 0
  case fullLock // = 1
  case roiLock // = 2
  case UNRECOGNIZED(Int)

  init() {
    self = .unlocked
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .unlocked
    case 1: self = .fullLock
    case 2: self = .roiLock
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .unlocked: return 0
    case .fullLock: return 1
    case .roiLock: return 2
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_ExposureLockMode: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_ExposureLockMode] = [
    .unlocked,
    .fullLock,
    .roiLock,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_ExposureMetering: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case standard // = 0
  case centerTop // = 1
  case UNRECOGNIZED(Int)

  init() {
    self = .standard
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .standard
    case 1: self = .centerTop
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .standard: return 0
    case .centerTop: return 1
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_ExposureMetering: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_ExposureMetering] = [
    .standard,
    .centerTop,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_ExposureMode: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case automatic // = 0
  case automaticPreferIsoSensitivity // = 1
  case automaticPreferShutterSpeed // = 2
  case manualIsoSensitivity // = 3
  case manualShutterSpeed // = 4
  case manual // = 5
  case UNRECOGNIZED(Int)

  init() {
    self = .automatic
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .automatic
    case 1: self = .automaticPreferIsoSensitivity
    case 2: self = .automaticPreferShutterSpeed
    case 3: self = .manualIsoSensitivity
    case 4: self = .manualShutterSpeed
    case 5: self = .manual
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .automatic: return 0
    case .automaticPreferIsoSensitivity: return 1
    case .automaticPreferShutterSpeed: return 2
    case .manualIsoSensitivity: return 3
    case .manualShutterSpeed: return 4
    case .manual: return 5
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_ExposureMode: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_ExposureMode] = [
    .automatic,
    .automaticPreferIsoSensitivity,
    .automaticPreferShutterSpeed,
    .manualIsoSensitivity,
    .manualShutterSpeed,
    .manual,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_Framerate: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case framerate24 // = 0
  case framerate25 // = 1
  case framerate30 // = 2
  case framerate48 // = 3
  case framerate50 // = 4
  case framerate60 // = 5
  case framerate96 // = 6
  case framerate100 // = 7
  case framerate120 // = 8
  case UNRECOGNIZED(Int)

  init() {
    self = .framerate24
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .framerate24
    case 1: self = .framerate25
    case 2: self = .framerate30
    case 3: self = .framerate48
    case 4: self = .framerate50
    case 5: self = .framerate60
    case 6: self = .framerate96
    case 7: self = .framerate100
    case 8: self = .framerate120
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .framerate24: return 0
    case .framerate25: return 1
    case .framerate30: return 2
    case .framerate48: return 3
    case .framerate50: return 4
    case .framerate60: return 5
    case .framerate96: return 6
    case .framerate100: return 7
    case .framerate120: return 8
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_Framerate: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_Framerate] = [
    .framerate24,
    .framerate25,
    .framerate30,
    .framerate48,
    .framerate50,
    .framerate60,
    .framerate96,
    .framerate100,
    .framerate120,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_ImageStyle: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case custom // = 0
  case standard // = 1
  case plog // = 2
  case intense // = 3
  case pastel // = 4
  case photogrammetry // = 5
  case UNRECOGNIZED(Int)

  init() {
    self = .custom
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .custom
    case 1: self = .standard
    case 2: self = .plog
    case 3: self = .intense
    case 4: self = .pastel
    case 5: self = .photogrammetry
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .custom: return 0
    case .standard: return 1
    case .plog: return 2
    case .intense: return 3
    case .pastel: return 4
    case .photogrammetry: return 5
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_ImageStyle: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_ImageStyle] = [
    .custom,
    .standard,
    .plog,
    .intense,
    .pastel,
    .photogrammetry,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_IsoSensitivity: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case isoSensitivity25 // = 0
  case isoSensitivity50 // = 1
  case isoSensitivity64 // = 2
  case isoSensitivity80 // = 3
  case isoSensitivity100 // = 4
  case isoSensitivity125 // = 5
  case isoSensitivity160 // = 6
  case isoSensitivity200 // = 7
  case isoSensitivity250 // = 8
  case isoSensitivity320 // = 9
  case isoSensitivity400 // = 10
  case isoSensitivity500 // = 11
  case isoSensitivity640 // = 12
  case isoSensitivity800 // = 13
  case isoSensitivity1000 // = 14
  case isoSensitivity1200 // = 15
  case isoSensitivity1600 // = 16
  case isoSensitivity2000 // = 17
  case isoSensitivity2500 // = 18
  case isoSensitivity3200 // = 19
  case isoSensitivity4000 // = 20
  case isoSensitivity5000 // = 21
  case isoSensitivity6400 // = 22
  case isoSensitivity8000 // = 23
  case isoSensitivity10000 // = 24
  case isoSensitivity12800 // = 25
  case isoSensitivity16000 // = 26
  case isoSensitivity20000 // = 27
  case isoSensitivity25600 // = 28
  case isoSensitivity32000 // = 29
  case isoSensitivity40000 // = 30
  case isoSensitivity51200 // = 31
  case UNRECOGNIZED(Int)

  init() {
    self = .isoSensitivity25
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .isoSensitivity25
    case 1: self = .isoSensitivity50
    case 2: self = .isoSensitivity64
    case 3: self = .isoSensitivity80
    case 4: self = .isoSensitivity100
    case 5: self = .isoSensitivity125
    case 6: self = .isoSensitivity160
    case 7: self = .isoSensitivity200
    case 8: self = .isoSensitivity250
    case 9: self = .isoSensitivity320
    case 10: self = .isoSensitivity400
    case 11: self = .isoSensitivity500
    case 12: self = .isoSensitivity640
    case 13: self = .isoSensitivity800
    case 14: self = .isoSensitivity1000
    case 15: self = .isoSensitivity1200
    case 16: self = .isoSensitivity1600
    case 17: self = .isoSensitivity2000
    case 18: self = .isoSensitivity2500
    case 19: self = .isoSensitivity3200
    case 20: self = .isoSensitivity4000
    case 21: self = .isoSensitivity5000
    case 22: self = .isoSensitivity6400
    case 23: self = .isoSensitivity8000
    case 24: self = .isoSensitivity10000
    case 25: self = .isoSensitivity12800
    case 26: self = .isoSensitivity16000
    case 27: self = .isoSensitivity20000
    case 28: self = .isoSensitivity25600
    case 29: self = .isoSensitivity32000
    case 30: self = .isoSensitivity40000
    case 31: self = .isoSensitivity51200
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .isoSensitivity25: return 0
    case .isoSensitivity50: return 1
    case .isoSensitivity64: return 2
    case .isoSensitivity80: return 3
    case .isoSensitivity100: return 4
    case .isoSensitivity125: return 5
    case .isoSensitivity160: return 6
    case .isoSensitivity200: return 7
    case .isoSensitivity250: return 8
    case .isoSensitivity320: return 9
    case .isoSensitivity400: return 10
    case .isoSensitivity500: return 11
    case .isoSensitivity640: return 12
    case .isoSensitivity800: return 13
    case .isoSensitivity1000: return 14
    case .isoSensitivity1200: return 15
    case .isoSensitivity1600: return 16
    case .isoSensitivity2000: return 17
    case .isoSensitivity2500: return 18
    case .isoSensitivity3200: return 19
    case .isoSensitivity4000: return 20
    case .isoSensitivity5000: return 21
    case .isoSensitivity6400: return 22
    case .isoSensitivity8000: return 23
    case .isoSensitivity10000: return 24
    case .isoSensitivity12800: return 25
    case .isoSensitivity16000: return 26
    case .isoSensitivity20000: return 27
    case .isoSensitivity25600: return 28
    case .isoSensitivity32000: return 29
    case .isoSensitivity40000: return 30
    case .isoSensitivity51200: return 31
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_IsoSensitivity: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_IsoSensitivity] = [
    .isoSensitivity25,
    .isoSensitivity50,
    .isoSensitivity64,
    .isoSensitivity80,
    .isoSensitivity100,
    .isoSensitivity125,
    .isoSensitivity160,
    .isoSensitivity200,
    .isoSensitivity250,
    .isoSensitivity320,
    .isoSensitivity400,
    .isoSensitivity500,
    .isoSensitivity640,
    .isoSensitivity800,
    .isoSensitivity1000,
    .isoSensitivity1200,
    .isoSensitivity1600,
    .isoSensitivity2000,
    .isoSensitivity2500,
    .isoSensitivity3200,
    .isoSensitivity4000,
    .isoSensitivity5000,
    .isoSensitivity6400,
    .isoSensitivity8000,
    .isoSensitivity10000,
    .isoSensitivity12800,
    .isoSensitivity16000,
    .isoSensitivity20000,
    .isoSensitivity25600,
    .isoSensitivity32000,
    .isoSensitivity40000,
    .isoSensitivity51200,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_PhotoState: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case unavailable // = 0
  case inactive // = 1
  case active // = 2
  case UNRECOGNIZED(Int)

  init() {
    self = .unavailable
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .unavailable
    case 1: self = .inactive
    case 2: self = .active
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .unavailable: return 0
    case .inactive: return 1
    case .active: return 2
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_PhotoState: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_PhotoState] = [
    .unavailable,
    .inactive,
    .active,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_PhotoEvent: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case start // = 0
  case takingPhoto // = 1
  case stop // = 4
  case UNRECOGNIZED(Int)

  init() {
    self = .start
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .start
    case 1: self = .takingPhoto
    case 4: self = .stop
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .start: return 0
    case .takingPhoto: return 1
    case .stop: return 4
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_PhotoEvent: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_PhotoEvent] = [
    .start,
    .takingPhoto,
    .stop,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_PhotoFileFormat: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case jpeg // = 0
  case dngJpeg // = 2
  case UNRECOGNIZED(Int)

  init() {
    self = .jpeg
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .jpeg
    case 2: self = .dngJpeg
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .jpeg: return 0
    case .dngJpeg: return 2
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_PhotoFileFormat: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_PhotoFileFormat] = [
    .jpeg,
    .dngJpeg,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_PhotoFormat: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case fullFrame // = 0
  case rectilinear // = 1
  case fullFrameStabilized // = 2
  case UNRECOGNIZED(Int)

  init() {
    self = .fullFrame
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .fullFrame
    case 1: self = .rectilinear
    case 2: self = .fullFrameStabilized
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .fullFrame: return 0
    case .rectilinear: return 1
    case .fullFrameStabilized: return 2
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_PhotoFormat: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_PhotoFormat] = [
    .fullFrame,
    .rectilinear,
    .fullFrameStabilized,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_PhotoMode: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case single // = 0
  case bracketing // = 1
  case burst // = 2
  case timeLapse // = 3
  case gpsLapse // = 4
  case UNRECOGNIZED(Int)

  init() {
    self = .single
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .single
    case 1: self = .bracketing
    case 2: self = .burst
    case 3: self = .timeLapse
    case 4: self = .gpsLapse
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .single: return 0
    case .bracketing: return 1
    case .burst: return 2
    case .timeLapse: return 3
    case .gpsLapse: return 4
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_PhotoMode: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_PhotoMode] = [
    .single,
    .bracketing,
    .burst,
    .timeLapse,
    .gpsLapse,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_PhotoResolution: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case photoResolution48MegaPixels // = 0
  case photoResolution12MegaPixels // = 2
  case UNRECOGNIZED(Int)

  init() {
    self = .photoResolution48MegaPixels
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .photoResolution48MegaPixels
    case 2: self = .photoResolution12MegaPixels
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .photoResolution48MegaPixels: return 0
    case .photoResolution12MegaPixels: return 2
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_PhotoResolution: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_PhotoResolution] = [
    .photoResolution48MegaPixels,
    .photoResolution12MegaPixels,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_PhotoStopReason: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case userRequest // = 0
  case captureDone // = 1
  case configurationChange // = 2
  case internalError // = 3
  case insufficientStorageSpace // = 4
  case UNRECOGNIZED(Int)

  init() {
    self = .userRequest
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .userRequest
    case 1: self = .captureDone
    case 2: self = .configurationChange
    case 3: self = .internalError
    case 4: self = .insufficientStorageSpace
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .userRequest: return 0
    case .captureDone: return 1
    case .configurationChange: return 2
    case .internalError: return 3
    case .insufficientStorageSpace: return 4
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_PhotoStopReason: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_PhotoStopReason] = [
    .userRequest,
    .captureDone,
    .configurationChange,
    .internalError,
    .insufficientStorageSpace,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_PhotoStreamingMode: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case interrupt // = 0
  case continuous // = 1
  case UNRECOGNIZED(Int)

  init() {
    self = .interrupt
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .interrupt
    case 1: self = .continuous
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .interrupt: return 0
    case .continuous: return 1
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_PhotoStreamingMode: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_PhotoStreamingMode] = [
    .interrupt,
    .continuous,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_RecordingEvent: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case start // = 0
  case stop // = 1
  case stopping // = 2
  case UNRECOGNIZED(Int)

  init() {
    self = .start
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .start
    case 1: self = .stop
    case 2: self = .stopping
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .start: return 0
    case .stop: return 1
    case .stopping: return 2
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_RecordingEvent: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_RecordingEvent] = [
    .start,
    .stop,
    .stopping,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_RecordingState: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case unavailable // = 0
  case inactive // = 1
  case active // = 3
  case UNRECOGNIZED(Int)

  init() {
    self = .unavailable
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .unavailable
    case 1: self = .inactive
    case 3: self = .active
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .unavailable: return 0
    case .inactive: return 1
    case .active: return 3
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_RecordingState: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_RecordingState] = [
    .unavailable,
    .inactive,
    .active,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_RecordingStopReason: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case userRequest // = 0
  case configurationChange // = 2
  case internalError // = 3
  case insufficientStorageSpace // = 4
  case insufficientStorageSpeed // = 5
  case UNRECOGNIZED(Int)

  init() {
    self = .userRequest
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .userRequest
    case 2: self = .configurationChange
    case 3: self = .internalError
    case 4: self = .insufficientStorageSpace
    case 5: self = .insufficientStorageSpeed
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .userRequest: return 0
    case .configurationChange: return 2
    case .internalError: return 3
    case .insufficientStorageSpace: return 4
    case .insufficientStorageSpeed: return 5
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_RecordingStopReason: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_RecordingStopReason] = [
    .userRequest,
    .configurationChange,
    .internalError,
    .insufficientStorageSpace,
    .insufficientStorageSpeed,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_VideoRecordingMode: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case standard // = 0
  case UNRECOGNIZED(Int)

  init() {
    self = .standard
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .standard
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .standard: return 0
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_VideoRecordingMode: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_VideoRecordingMode] = [
    .standard,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_ShutterSpeed: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case shutterSpeed1Over10000 // = 0
  case shutterSpeed1Over8000 // = 1
  case shutterSpeed1Over6400 // = 2
  case shutterSpeed1Over5000 // = 3
  case shutterSpeed1Over4000 // = 4
  case shutterSpeed1Over3200 // = 5
  case shutterSpeed1Over2500 // = 6
  case shutterSpeed1Over2000 // = 7
  case shutterSpeed1Over1600 // = 8
  case shutterSpeed1Over1250 // = 9
  case shutterSpeed1Over1000 // = 10
  case shutterSpeed1Over800 // = 11
  case shutterSpeed1Over640 // = 12
  case shutterSpeed1Over500 // = 13
  case shutterSpeed1Over400 // = 14
  case shutterSpeed1Over320 // = 15
  case shutterSpeed1Over240 // = 16
  case shutterSpeed1Over200 // = 17
  case shutterSpeed1Over160 // = 18
  case shutterSpeed1Over120 // = 19
  case shutterSpeed1Over100 // = 20
  case shutterSpeed1Over80 // = 21
  case shutterSpeed1Over60 // = 22
  case shutterSpeed1Over50 // = 23
  case shutterSpeed1Over40 // = 24
  case shutterSpeed1Over30 // = 25
  case shutterSpeed1Over25 // = 26
  case shutterSpeed1Over15 // = 27
  case shutterSpeed1Over10 // = 28
  case shutterSpeed1Over8 // = 29
  case shutterSpeed1Over6 // = 30
  case shutterSpeed1Over4 // = 31
  case shutterSpeed1Over3 // = 32
  case shutterSpeed1Over2 // = 33
  case shutterSpeed1Over1Point5 // = 34
  case shutterSpeed1 // = 35
  case UNRECOGNIZED(Int)

  init() {
    self = .shutterSpeed1Over10000
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .shutterSpeed1Over10000
    case 1: self = .shutterSpeed1Over8000
    case 2: self = .shutterSpeed1Over6400
    case 3: self = .shutterSpeed1Over5000
    case 4: self = .shutterSpeed1Over4000
    case 5: self = .shutterSpeed1Over3200
    case 6: self = .shutterSpeed1Over2500
    case 7: self = .shutterSpeed1Over2000
    case 8: self = .shutterSpeed1Over1600
    case 9: self = .shutterSpeed1Over1250
    case 10: self = .shutterSpeed1Over1000
    case 11: self = .shutterSpeed1Over800
    case 12: self = .shutterSpeed1Over640
    case 13: self = .shutterSpeed1Over500
    case 14: self = .shutterSpeed1Over400
    case 15: self = .shutterSpeed1Over320
    case 16: self = .shutterSpeed1Over240
    case 17: self = .shutterSpeed1Over200
    case 18: self = .shutterSpeed1Over160
    case 19: self = .shutterSpeed1Over120
    case 20: self = .shutterSpeed1Over100
    case 21: self = .shutterSpeed1Over80
    case 22: self = .shutterSpeed1Over60
    case 23: self = .shutterSpeed1Over50
    case 24: self = .shutterSpeed1Over40
    case 25: self = .shutterSpeed1Over30
    case 26: self = .shutterSpeed1Over25
    case 27: self = .shutterSpeed1Over15
    case 28: self = .shutterSpeed1Over10
    case 29: self = .shutterSpeed1Over8
    case 30: self = .shutterSpeed1Over6
    case 31: self = .shutterSpeed1Over4
    case 32: self = .shutterSpeed1Over3
    case 33: self = .shutterSpeed1Over2
    case 34: self = .shutterSpeed1Over1Point5
    case 35: self = .shutterSpeed1
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .shutterSpeed1Over10000: return 0
    case .shutterSpeed1Over8000: return 1
    case .shutterSpeed1Over6400: return 2
    case .shutterSpeed1Over5000: return 3
    case .shutterSpeed1Over4000: return 4
    case .shutterSpeed1Over3200: return 5
    case .shutterSpeed1Over2500: return 6
    case .shutterSpeed1Over2000: return 7
    case .shutterSpeed1Over1600: return 8
    case .shutterSpeed1Over1250: return 9
    case .shutterSpeed1Over1000: return 10
    case .shutterSpeed1Over800: return 11
    case .shutterSpeed1Over640: return 12
    case .shutterSpeed1Over500: return 13
    case .shutterSpeed1Over400: return 14
    case .shutterSpeed1Over320: return 15
    case .shutterSpeed1Over240: return 16
    case .shutterSpeed1Over200: return 17
    case .shutterSpeed1Over160: return 18
    case .shutterSpeed1Over120: return 19
    case .shutterSpeed1Over100: return 20
    case .shutterSpeed1Over80: return 21
    case .shutterSpeed1Over60: return 22
    case .shutterSpeed1Over50: return 23
    case .shutterSpeed1Over40: return 24
    case .shutterSpeed1Over30: return 25
    case .shutterSpeed1Over25: return 26
    case .shutterSpeed1Over15: return 27
    case .shutterSpeed1Over10: return 28
    case .shutterSpeed1Over8: return 29
    case .shutterSpeed1Over6: return 30
    case .shutterSpeed1Over4: return 31
    case .shutterSpeed1Over3: return 32
    case .shutterSpeed1Over2: return 33
    case .shutterSpeed1Over1Point5: return 34
    case .shutterSpeed1: return 35
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_ShutterSpeed: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_ShutterSpeed] = [
    .shutterSpeed1Over10000,
    .shutterSpeed1Over8000,
    .shutterSpeed1Over6400,
    .shutterSpeed1Over5000,
    .shutterSpeed1Over4000,
    .shutterSpeed1Over3200,
    .shutterSpeed1Over2500,
    .shutterSpeed1Over2000,
    .shutterSpeed1Over1600,
    .shutterSpeed1Over1250,
    .shutterSpeed1Over1000,
    .shutterSpeed1Over800,
    .shutterSpeed1Over640,
    .shutterSpeed1Over500,
    .shutterSpeed1Over400,
    .shutterSpeed1Over320,
    .shutterSpeed1Over240,
    .shutterSpeed1Over200,
    .shutterSpeed1Over160,
    .shutterSpeed1Over120,
    .shutterSpeed1Over100,
    .shutterSpeed1Over80,
    .shutterSpeed1Over60,
    .shutterSpeed1Over50,
    .shutterSpeed1Over40,
    .shutterSpeed1Over30,
    .shutterSpeed1Over25,
    .shutterSpeed1Over15,
    .shutterSpeed1Over10,
    .shutterSpeed1Over8,
    .shutterSpeed1Over6,
    .shutterSpeed1Over4,
    .shutterSpeed1Over3,
    .shutterSpeed1Over2,
    .shutterSpeed1Over1Point5,
    .shutterSpeed1,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_StoragePolicy: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case auto // = 0
  case `internal` // = 1
  case removable // = 2
  case UNRECOGNIZED(Int)

  init() {
    self = .auto
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .auto
    case 1: self = .internal
    case 2: self = .removable
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .auto: return 0
    case .internal: return 1
    case .removable: return 2
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_StoragePolicy: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_StoragePolicy] = [
    .auto,
    .internal,
    .removable,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_StorageType: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case `internal` // = 0
  case removable // = 1
  case UNRECOGNIZED(Int)

  init() {
    self = .internal
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .internal
    case 1: self = .removable
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .internal: return 0
    case .removable: return 1
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_StorageType: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_StorageType] = [
    .internal,
    .removable,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_VideoCodec: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case h264 // = 0
  case h265 // = 1
  case UNRECOGNIZED(Int)

  init() {
    self = .h264
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .h264
    case 1: self = .h265
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .h264: return 0
    case .h265: return 1
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_VideoCodec: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_VideoCodec] = [
    .h264,
    .h265,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_VideoResolution: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case reserved // = 0
  case videoResolution2160P // = 1
  case videoResolution1080P // = 3
  case UNRECOGNIZED(Int)

  init() {
    self = .reserved
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .reserved
    case 1: self = .videoResolution2160P
    case 3: self = .videoResolution1080P
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .reserved: return 0
    case .videoResolution2160P: return 1
    case .videoResolution1080P: return 3
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_VideoResolution: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_VideoResolution] = [
    .reserved,
    .videoResolution2160P,
    .videoResolution1080P,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_WhiteBalanceLockMode: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case unlocked // = 0
  case locked // = 1
  case UNRECOGNIZED(Int)

  init() {
    self = .unlocked
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .unlocked
    case 1: self = .locked
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .unlocked: return 0
    case .locked: return 1
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_WhiteBalanceLockMode: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_WhiteBalanceLockMode] = [
    .unlocked,
    .locked,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_WhiteBalanceMode: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case custom // = 0
  case automatic // = 1
  case candle // = 2
  case sunset // = 3
  case incandescent // = 4
  case warmWhiteFluorescent // = 5
  case halogen // = 6
  case fluorescent // = 7
  case coolWhiteFluorescent // = 8
  case flash // = 9
  case daylight // = 10
  case sunny // = 11
  case cloudy // = 12
  case snow // = 13
  case hazy // = 14
  case shaded // = 15
  case greenFoliage // = 16
  case blueSky // = 17
  case UNRECOGNIZED(Int)

  init() {
    self = .custom
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .custom
    case 1: self = .automatic
    case 2: self = .candle
    case 3: self = .sunset
    case 4: self = .incandescent
    case 5: self = .warmWhiteFluorescent
    case 6: self = .halogen
    case 7: self = .fluorescent
    case 8: self = .coolWhiteFluorescent
    case 9: self = .flash
    case 10: self = .daylight
    case 11: self = .sunny
    case 12: self = .cloudy
    case 13: self = .snow
    case 14: self = .hazy
    case 15: self = .shaded
    case 16: self = .greenFoliage
    case 17: self = .blueSky
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .custom: return 0
    case .automatic: return 1
    case .candle: return 2
    case .sunset: return 3
    case .incandescent: return 4
    case .warmWhiteFluorescent: return 5
    case .halogen: return 6
    case .fluorescent: return 7
    case .coolWhiteFluorescent: return 8
    case .flash: return 9
    case .daylight: return 10
    case .sunny: return 11
    case .cloudy: return 12
    case .snow: return 13
    case .hazy: return 14
    case .shaded: return 15
    case .greenFoliage: return 16
    case .blueSky: return 17
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_WhiteBalanceMode: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_WhiteBalanceMode] = [
    .custom,
    .automatic,
    .candle,
    .sunset,
    .incandescent,
    .warmWhiteFluorescent,
    .halogen,
    .fluorescent,
    .coolWhiteFluorescent,
    .flash,
    .daylight,
    .sunny,
    .cloudy,
    .snow,
    .hazy,
    .shaded,
    .greenFoliage,
    .blueSky,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_WhiteBalanceTemperature: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case whiteBalanceTemperature1500 // = 0
  case whiteBalanceTemperature1750 // = 1
  case whiteBalanceTemperature2000 // = 2
  case whiteBalanceTemperature2250 // = 3
  case whiteBalanceTemperature2500 // = 4
  case whiteBalanceTemperature2750 // = 5
  case whiteBalanceTemperature3000 // = 6
  case whiteBalanceTemperature3250 // = 7
  case whiteBalanceTemperature3500 // = 8
  case whiteBalanceTemperature3750 // = 9
  case whiteBalanceTemperature4000 // = 10
  case whiteBalanceTemperature4250 // = 11
  case whiteBalanceTemperature4500 // = 12
  case whiteBalanceTemperature4750 // = 13
  case whiteBalanceTemperature5000 // = 14
  case whiteBalanceTemperature5250 // = 15
  case whiteBalanceTemperature5500 // = 16
  case whiteBalanceTemperature5750 // = 17
  case whiteBalanceTemperature6000 // = 18
  case whiteBalanceTemperature6250 // = 19
  case whiteBalanceTemperature6500 // = 20
  case whiteBalanceTemperature6750 // = 21
  case whiteBalanceTemperature7000 // = 22
  case whiteBalanceTemperature7250 // = 23
  case whiteBalanceTemperature7500 // = 24
  case whiteBalanceTemperature7750 // = 25
  case whiteBalanceTemperature8000 // = 26
  case whiteBalanceTemperature8250 // = 27
  case whiteBalanceTemperature8500 // = 28
  case whiteBalanceTemperature8750 // = 29
  case whiteBalanceTemperature9000 // = 30
  case whiteBalanceTemperature9250 // = 31
  case whiteBalanceTemperature9500 // = 32
  case whiteBalanceTemperature9750 // = 33
  case whiteBalanceTemperature10000 // = 34
  case whiteBalanceTemperature10250 // = 35
  case whiteBalanceTemperature10500 // = 36
  case whiteBalanceTemperature10750 // = 37
  case whiteBalanceTemperature11000 // = 38
  case whiteBalanceTemperature11250 // = 39
  case whiteBalanceTemperature11500 // = 40
  case whiteBalanceTemperature11750 // = 41
  case whiteBalanceTemperature12000 // = 42
  case whiteBalanceTemperature12250 // = 43
  case whiteBalanceTemperature12500 // = 44
  case whiteBalanceTemperature12750 // = 45
  case whiteBalanceTemperature13000 // = 46
  case whiteBalanceTemperature13250 // = 47
  case whiteBalanceTemperature13500 // = 48
  case whiteBalanceTemperature13750 // = 49
  case whiteBalanceTemperature14000 // = 50
  case whiteBalanceTemperature14250 // = 51
  case whiteBalanceTemperature14500 // = 52
  case whiteBalanceTemperature14750 // = 53
  case whiteBalanceTemperature15000 // = 54
  case UNRECOGNIZED(Int)

  init() {
    self = .whiteBalanceTemperature1500
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .whiteBalanceTemperature1500
    case 1: self = .whiteBalanceTemperature1750
    case 2: self = .whiteBalanceTemperature2000
    case 3: self = .whiteBalanceTemperature2250
    case 4: self = .whiteBalanceTemperature2500
    case 5: self = .whiteBalanceTemperature2750
    case 6: self = .whiteBalanceTemperature3000
    case 7: self = .whiteBalanceTemperature3250
    case 8: self = .whiteBalanceTemperature3500
    case 9: self = .whiteBalanceTemperature3750
    case 10: self = .whiteBalanceTemperature4000
    case 11: self = .whiteBalanceTemperature4250
    case 12: self = .whiteBalanceTemperature4500
    case 13: self = .whiteBalanceTemperature4750
    case 14: self = .whiteBalanceTemperature5000
    case 15: self = .whiteBalanceTemperature5250
    case 16: self = .whiteBalanceTemperature5500
    case 17: self = .whiteBalanceTemperature5750
    case 18: self = .whiteBalanceTemperature6000
    case 19: self = .whiteBalanceTemperature6250
    case 20: self = .whiteBalanceTemperature6500
    case 21: self = .whiteBalanceTemperature6750
    case 22: self = .whiteBalanceTemperature7000
    case 23: self = .whiteBalanceTemperature7250
    case 24: self = .whiteBalanceTemperature7500
    case 25: self = .whiteBalanceTemperature7750
    case 26: self = .whiteBalanceTemperature8000
    case 27: self = .whiteBalanceTemperature8250
    case 28: self = .whiteBalanceTemperature8500
    case 29: self = .whiteBalanceTemperature8750
    case 30: self = .whiteBalanceTemperature9000
    case 31: self = .whiteBalanceTemperature9250
    case 32: self = .whiteBalanceTemperature9500
    case 33: self = .whiteBalanceTemperature9750
    case 34: self = .whiteBalanceTemperature10000
    case 35: self = .whiteBalanceTemperature10250
    case 36: self = .whiteBalanceTemperature10500
    case 37: self = .whiteBalanceTemperature10750
    case 38: self = .whiteBalanceTemperature11000
    case 39: self = .whiteBalanceTemperature11250
    case 40: self = .whiteBalanceTemperature11500
    case 41: self = .whiteBalanceTemperature11750
    case 42: self = .whiteBalanceTemperature12000
    case 43: self = .whiteBalanceTemperature12250
    case 44: self = .whiteBalanceTemperature12500
    case 45: self = .whiteBalanceTemperature12750
    case 46: self = .whiteBalanceTemperature13000
    case 47: self = .whiteBalanceTemperature13250
    case 48: self = .whiteBalanceTemperature13500
    case 49: self = .whiteBalanceTemperature13750
    case 50: self = .whiteBalanceTemperature14000
    case 51: self = .whiteBalanceTemperature14250
    case 52: self = .whiteBalanceTemperature14500
    case 53: self = .whiteBalanceTemperature14750
    case 54: self = .whiteBalanceTemperature15000
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .whiteBalanceTemperature1500: return 0
    case .whiteBalanceTemperature1750: return 1
    case .whiteBalanceTemperature2000: return 2
    case .whiteBalanceTemperature2250: return 3
    case .whiteBalanceTemperature2500: return 4
    case .whiteBalanceTemperature2750: return 5
    case .whiteBalanceTemperature3000: return 6
    case .whiteBalanceTemperature3250: return 7
    case .whiteBalanceTemperature3500: return 8
    case .whiteBalanceTemperature3750: return 9
    case .whiteBalanceTemperature4000: return 10
    case .whiteBalanceTemperature4250: return 11
    case .whiteBalanceTemperature4500: return 12
    case .whiteBalanceTemperature4750: return 13
    case .whiteBalanceTemperature5000: return 14
    case .whiteBalanceTemperature5250: return 15
    case .whiteBalanceTemperature5500: return 16
    case .whiteBalanceTemperature5750: return 17
    case .whiteBalanceTemperature6000: return 18
    case .whiteBalanceTemperature6250: return 19
    case .whiteBalanceTemperature6500: return 20
    case .whiteBalanceTemperature6750: return 21
    case .whiteBalanceTemperature7000: return 22
    case .whiteBalanceTemperature7250: return 23
    case .whiteBalanceTemperature7500: return 24
    case .whiteBalanceTemperature7750: return 25
    case .whiteBalanceTemperature8000: return 26
    case .whiteBalanceTemperature8250: return 27
    case .whiteBalanceTemperature8500: return 28
    case .whiteBalanceTemperature8750: return 29
    case .whiteBalanceTemperature9000: return 30
    case .whiteBalanceTemperature9250: return 31
    case .whiteBalanceTemperature9500: return 32
    case .whiteBalanceTemperature9750: return 33
    case .whiteBalanceTemperature10000: return 34
    case .whiteBalanceTemperature10250: return 35
    case .whiteBalanceTemperature10500: return 36
    case .whiteBalanceTemperature10750: return 37
    case .whiteBalanceTemperature11000: return 38
    case .whiteBalanceTemperature11250: return 39
    case .whiteBalanceTemperature11500: return 40
    case .whiteBalanceTemperature11750: return 41
    case .whiteBalanceTemperature12000: return 42
    case .whiteBalanceTemperature12250: return 43
    case .whiteBalanceTemperature12500: return 44
    case .whiteBalanceTemperature12750: return 45
    case .whiteBalanceTemperature13000: return 46
    case .whiteBalanceTemperature13250: return 47
    case .whiteBalanceTemperature13500: return 48
    case .whiteBalanceTemperature13750: return 49
    case .whiteBalanceTemperature14000: return 50
    case .whiteBalanceTemperature14250: return 51
    case .whiteBalanceTemperature14500: return 52
    case .whiteBalanceTemperature14750: return 53
    case .whiteBalanceTemperature15000: return 54
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_WhiteBalanceTemperature: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_WhiteBalanceTemperature] = [
    .whiteBalanceTemperature1500,
    .whiteBalanceTemperature1750,
    .whiteBalanceTemperature2000,
    .whiteBalanceTemperature2250,
    .whiteBalanceTemperature2500,
    .whiteBalanceTemperature2750,
    .whiteBalanceTemperature3000,
    .whiteBalanceTemperature3250,
    .whiteBalanceTemperature3500,
    .whiteBalanceTemperature3750,
    .whiteBalanceTemperature4000,
    .whiteBalanceTemperature4250,
    .whiteBalanceTemperature4500,
    .whiteBalanceTemperature4750,
    .whiteBalanceTemperature5000,
    .whiteBalanceTemperature5250,
    .whiteBalanceTemperature5500,
    .whiteBalanceTemperature5750,
    .whiteBalanceTemperature6000,
    .whiteBalanceTemperature6250,
    .whiteBalanceTemperature6500,
    .whiteBalanceTemperature6750,
    .whiteBalanceTemperature7000,
    .whiteBalanceTemperature7250,
    .whiteBalanceTemperature7500,
    .whiteBalanceTemperature7750,
    .whiteBalanceTemperature8000,
    .whiteBalanceTemperature8250,
    .whiteBalanceTemperature8500,
    .whiteBalanceTemperature8750,
    .whiteBalanceTemperature9000,
    .whiteBalanceTemperature9250,
    .whiteBalanceTemperature9500,
    .whiteBalanceTemperature9750,
    .whiteBalanceTemperature10000,
    .whiteBalanceTemperature10250,
    .whiteBalanceTemperature10500,
    .whiteBalanceTemperature10750,
    .whiteBalanceTemperature11000,
    .whiteBalanceTemperature11250,
    .whiteBalanceTemperature11500,
    .whiteBalanceTemperature11750,
    .whiteBalanceTemperature12000,
    .whiteBalanceTemperature12250,
    .whiteBalanceTemperature12500,
    .whiteBalanceTemperature12750,
    .whiteBalanceTemperature13000,
    .whiteBalanceTemperature13250,
    .whiteBalanceTemperature13500,
    .whiteBalanceTemperature13750,
    .whiteBalanceTemperature14000,
    .whiteBalanceTemperature14250,
    .whiteBalanceTemperature14500,
    .whiteBalanceTemperature14750,
    .whiteBalanceTemperature15000,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_ZoomControlMode: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case level // = 0
  case velocity // = 1
  case UNRECOGNIZED(Int)

  init() {
    self = .level
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .level
    case 1: self = .velocity
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .level: return 0
    case .velocity: return 1
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_ZoomControlMode: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_ZoomControlMode] = [
    .level,
    .velocity,
  ]
}

#endif  // swift(>=4.2)

enum Arsdk_Camera_ZoomVelocityControlQualityMode: SwiftProtobuf.Enum {
  typealias RawValue = Int
  case allowDegradation // = 0
  case stopBeforeDegradation // = 1
  case UNRECOGNIZED(Int)

  init() {
    self = .allowDegradation
  }

  init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .allowDegradation
    case 1: self = .stopBeforeDegradation
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  var rawValue: Int {
    switch self {
    case .allowDegradation: return 0
    case .stopBeforeDegradation: return 1
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Arsdk_Camera_ZoomVelocityControlQualityMode: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  static var allCases: [Arsdk_Camera_ZoomVelocityControlQualityMode] = [
    .allowDegradation,
    .stopBeforeDegradation,
  ]
}

#endif  // swift(>=4.2)

/// This is the entry point to send messages to the drone
struct Arsdk_Camera_Command {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  var id: Arsdk_Camera_Command.OneOf_ID? = nil

  /// non-ack
  var setZoomTarget: Arsdk_Camera_Command.SetZoomTarget {
    get {
      if case .setZoomTarget(let v)? = id {return v}
      return Arsdk_Camera_Command.SetZoomTarget()
    }
    set {id = .setZoomTarget(newValue)}
  }

  var listCameras: Arsdk_Camera_Command.ListCameras {
    get {
      if case .listCameras(let v)? = id {return v}
      return Arsdk_Camera_Command.ListCameras()
    }
    set {id = .listCameras(newValue)}
  }

  var getState: Arsdk_Camera_Command.GetState {
    get {
      if case .getState(let v)? = id {return v}
      return Arsdk_Camera_Command.GetState()
    }
    set {id = .getState(newValue)}
  }

  var configure: Arsdk_Camera_Command.Configure {
    get {
      if case .configure(let v)? = id {return v}
      return Arsdk_Camera_Command.Configure()
    }
    set {id = .configure(newValue)}
  }

  var startPhoto: Arsdk_Camera_Command.StartPhoto {
    get {
      if case .startPhoto(let v)? = id {return v}
      return Arsdk_Camera_Command.StartPhoto()
    }
    set {id = .startPhoto(newValue)}
  }

  var stopPhoto: Arsdk_Camera_Command.StopPhoto {
    get {
      if case .stopPhoto(let v)? = id {return v}
      return Arsdk_Camera_Command.StopPhoto()
    }
    set {id = .stopPhoto(newValue)}
  }

  var startRecording: Arsdk_Camera_Command.StartRecording {
    get {
      if case .startRecording(let v)? = id {return v}
      return Arsdk_Camera_Command.StartRecording()
    }
    set {id = .startRecording(newValue)}
  }

  var stopRecording: Arsdk_Camera_Command.StopRecording {
    get {
      if case .stopRecording(let v)? = id {return v}
      return Arsdk_Camera_Command.StopRecording()
    }
    set {id = .stopRecording(newValue)}
  }

  var lockExposure: Arsdk_Camera_Command.LockExposure {
    get {
      if case .lockExposure(let v)? = id {return v}
      return Arsdk_Camera_Command.LockExposure()
    }
    set {id = .lockExposure(newValue)}
  }

  var lockWhiteBalance: Arsdk_Camera_Command.LockWhiteBalance {
    get {
      if case .lockWhiteBalance(let v)? = id {return v}
      return Arsdk_Camera_Command.LockWhiteBalance()
    }
    set {id = .lockWhiteBalance(newValue)}
  }

  var setMediaMetadata: Arsdk_Camera_Command.SetMediaMetadata {
    get {
      if case .setMediaMetadata(let v)? = id {return v}
      return Arsdk_Camera_Command.SetMediaMetadata()
    }
    set {id = .setMediaMetadata(newValue)}
  }

  var resetZoom: Arsdk_Camera_Command.ResetZoom {
    get {
      if case .resetZoom(let v)? = id {return v}
      return Arsdk_Camera_Command.ResetZoom()
    }
    set {id = .resetZoom(newValue)}
  }

  var unknownFields = SwiftProtobuf.UnknownStorage()

  enum OneOf_ID: Equatable {
    /// non-ack
    case setZoomTarget(Arsdk_Camera_Command.SetZoomTarget)
    case listCameras(Arsdk_Camera_Command.ListCameras)
    case getState(Arsdk_Camera_Command.GetState)
    case configure(Arsdk_Camera_Command.Configure)
    case startPhoto(Arsdk_Camera_Command.StartPhoto)
    case stopPhoto(Arsdk_Camera_Command.StopPhoto)
    case startRecording(Arsdk_Camera_Command.StartRecording)
    case stopRecording(Arsdk_Camera_Command.StopRecording)
    case lockExposure(Arsdk_Camera_Command.LockExposure)
    case lockWhiteBalance(Arsdk_Camera_Command.LockWhiteBalance)
    case setMediaMetadata(Arsdk_Camera_Command.SetMediaMetadata)
    case resetZoom(Arsdk_Camera_Command.ResetZoom)

  #if !swift(>=4.1)
    static func ==(lhs: Arsdk_Camera_Command.OneOf_ID, rhs: Arsdk_Camera_Command.OneOf_ID) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.setZoomTarget, .setZoomTarget): return {
        guard case .setZoomTarget(let l) = lhs, case .setZoomTarget(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.listCameras, .listCameras): return {
        guard case .listCameras(let l) = lhs, case .listCameras(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.getState, .getState): return {
        guard case .getState(let l) = lhs, case .getState(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.configure, .configure): return {
        guard case .configure(let l) = lhs, case .configure(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.startPhoto, .startPhoto): return {
        guard case .startPhoto(let l) = lhs, case .startPhoto(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.stopPhoto, .stopPhoto): return {
        guard case .stopPhoto(let l) = lhs, case .stopPhoto(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.startRecording, .startRecording): return {
        guard case .startRecording(let l) = lhs, case .startRecording(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.stopRecording, .stopRecording): return {
        guard case .stopRecording(let l) = lhs, case .stopRecording(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.lockExposure, .lockExposure): return {
        guard case .lockExposure(let l) = lhs, case .lockExposure(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.lockWhiteBalance, .lockWhiteBalance): return {
        guard case .lockWhiteBalance(let l) = lhs, case .lockWhiteBalance(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.setMediaMetadata, .setMediaMetadata): return {
        guard case .setMediaMetadata(let l) = lhs, case .setMediaMetadata(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.resetZoom, .resetZoom): return {
        guard case .resetZoom(let l) = lhs, case .resetZoom(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  struct ListCameras {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var modelFilter: [Arsdk_Camera_CameraModel] = []

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  struct GetState {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var cameraID: UInt64 = 0

    var includeDefaultCapabilities: Bool = false

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  struct Configure {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var cameraID: UInt64 = 0

    var config: Arsdk_Camera_Config {
      get {return _config ?? Arsdk_Camera_Config()}
      set {_config = newValue}
    }
    /// Returns true if `config` has been explicitly set.
    var hasConfig: Bool {return self._config != nil}
    /// Clears the value of `config`. Subsequent reads from it will return its default value.
    mutating func clearConfig() {self._config = nil}

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}

    fileprivate var _config: Arsdk_Camera_Config? = nil
  }

  struct SetZoomTarget {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var cameraID: UInt64 = 0

    var controlMode: Arsdk_Camera_ZoomControlMode = .level

    var target: Double = 0

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  struct ResetZoom {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var cameraID: UInt64 = 0

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  struct StartPhoto {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var cameraID: UInt64 = 0

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  struct StopPhoto {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var cameraID: UInt64 = 0

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  struct StartRecording {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var cameraID: UInt64 = 0

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  struct StopRecording {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var cameraID: UInt64 = 0

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  struct LockExposure {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var cameraID: UInt64 = 0

    var mode: Arsdk_Camera_ExposureLockMode = .unlocked

    var roi: Arsdk_Camera_ExposureRoi.Center {
      get {return _roi ?? Arsdk_Camera_ExposureRoi.Center()}
      set {_roi = newValue}
    }
    /// Returns true if `roi` has been explicitly set.
    var hasRoi: Bool {return self._roi != nil}
    /// Clears the value of `roi`. Subsequent reads from it will return its default value.
    mutating func clearRoi() {self._roi = nil}

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}

    fileprivate var _roi: Arsdk_Camera_ExposureRoi.Center? = nil
  }

  struct LockWhiteBalance {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var cameraID: UInt64 = 0

    var mode: Arsdk_Camera_WhiteBalanceLockMode = .unlocked

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  struct SetMediaMetadata {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var cameraID: UInt64 = 0

    var metadata: Arsdk_Camera_MediaMetadata {
      get {return _metadata ?? Arsdk_Camera_MediaMetadata()}
      set {_metadata = newValue}
    }
    /// Returns true if `metadata` has been explicitly set.
    var hasMetadata: Bool {return self._metadata != nil}
    /// Clears the value of `metadata`. Subsequent reads from it will return its default value.
    mutating func clearMetadata() {self._metadata = nil}

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}

    fileprivate var _metadata: Arsdk_Camera_MediaMetadata? = nil
  }

  init() {}
}

/// This is the entry point to receive messages from the drone
struct Arsdk_Camera_Event {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  var id: Arsdk_Camera_Event.OneOf_ID? = nil

  /// non-ack
  var cameraExposure: Arsdk_Camera_Event.Exposure {
    get {
      if case .cameraExposure(let v)? = id {return v}
      return Arsdk_Camera_Event.Exposure()
    }
    set {id = .cameraExposure(newValue)}
  }

  /// non-ack
  var zoomLevel: Arsdk_Camera_Event.ZoomLevel {
    get {
      if case .zoomLevel(let v)? = id {return v}
      return Arsdk_Camera_Event.ZoomLevel()
    }
    set {id = .zoomLevel(newValue)}
  }

  /// non-ack
  var nextPhotoInterval: Arsdk_Camera_Event.NextPhotoInterval {
    get {
      if case .nextPhotoInterval(let v)? = id {return v}
      return Arsdk_Camera_Event.NextPhotoInterval()
    }
    set {id = .nextPhotoInterval(newValue)}
  }

  var cameraList: Arsdk_Camera_Event.CameraList {
    get {
      if case .cameraList(let v)? = id {return v}
      return Arsdk_Camera_Event.CameraList()
    }
    set {id = .cameraList(newValue)}
  }

  var state: Arsdk_Camera_Event.State {
    get {
      if case .state(let v)? = id {return v}
      return Arsdk_Camera_Event.State()
    }
    set {id = .state(newValue)}
  }

  var photo: Arsdk_Camera_Event.Photo {
    get {
      if case .photo(let v)? = id {return v}
      return Arsdk_Camera_Event.Photo()
    }
    set {id = .photo(newValue)}
  }

  var recording: Arsdk_Camera_Event.Recording {
    get {
      if case .recording(let v)? = id {return v}
      return Arsdk_Camera_Event.Recording()
    }
    set {id = .recording(newValue)}
  }

  var unknownFields = SwiftProtobuf.UnknownStorage()

  enum OneOf_ID: Equatable {
    /// non-ack
    case cameraExposure(Arsdk_Camera_Event.Exposure)
    /// non-ack
    case zoomLevel(Arsdk_Camera_Event.ZoomLevel)
    /// non-ack
    case nextPhotoInterval(Arsdk_Camera_Event.NextPhotoInterval)
    case cameraList(Arsdk_Camera_Event.CameraList)
    case state(Arsdk_Camera_Event.State)
    case photo(Arsdk_Camera_Event.Photo)
    case recording(Arsdk_Camera_Event.Recording)

  #if !swift(>=4.1)
    static func ==(lhs: Arsdk_Camera_Event.OneOf_ID, rhs: Arsdk_Camera_Event.OneOf_ID) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.cameraExposure, .cameraExposure): return {
        guard case .cameraExposure(let l) = lhs, case .cameraExposure(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.zoomLevel, .zoomLevel): return {
        guard case .zoomLevel(let l) = lhs, case .zoomLevel(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.nextPhotoInterval, .nextPhotoInterval): return {
        guard case .nextPhotoInterval(let l) = lhs, case .nextPhotoInterval(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.cameraList, .cameraList): return {
        guard case .cameraList(let l) = lhs, case .cameraList(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.state, .state): return {
        guard case .state(let l) = lhs, case .state(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.photo, .photo): return {
        guard case .photo(let l) = lhs, case .photo(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.recording, .recording): return {
        guard case .recording(let l) = lhs, case .recording(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  struct CameraList {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var cameras: Dictionary<UInt64,Arsdk_Camera_CameraModel> = [:]

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  struct State {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var cameraID: UInt64 {
      get {return _storage._cameraID}
      set {_uniqueStorage()._cameraID = newValue}
    }

    var selectedFields: Dictionary<UInt32,SwiftProtobuf.Google_Protobuf_Empty> {
      get {return _storage._selectedFields}
      set {_uniqueStorage()._selectedFields = newValue}
    }

    var active: Bool {
      get {return _storage._active}
      set {_uniqueStorage()._active = newValue}
    }

    var defaultCapabilities: Arsdk_Camera_Capabilities {
      get {return _storage._defaultCapabilities ?? Arsdk_Camera_Capabilities()}
      set {_uniqueStorage()._defaultCapabilities = newValue}
    }
    /// Returns true if `defaultCapabilities` has been explicitly set.
    var hasDefaultCapabilities: Bool {return _storage._defaultCapabilities != nil}
    /// Clears the value of `defaultCapabilities`. Subsequent reads from it will return its default value.
    mutating func clearDefaultCapabilities() {_uniqueStorage()._defaultCapabilities = nil}

    var currentCapabilities: Arsdk_Camera_Capabilities {
      get {return _storage._currentCapabilities ?? Arsdk_Camera_Capabilities()}
      set {_uniqueStorage()._currentCapabilities = newValue}
    }
    /// Returns true if `currentCapabilities` has been explicitly set.
    var hasCurrentCapabilities: Bool {return _storage._currentCapabilities != nil}
    /// Clears the value of `currentCapabilities`. Subsequent reads from it will return its default value.
    mutating func clearCurrentCapabilities() {_uniqueStorage()._currentCapabilities = nil}

    var config: Arsdk_Camera_Config {
      get {return _storage._config ?? Arsdk_Camera_Config()}
      set {_uniqueStorage()._config = newValue}
    }
    /// Returns true if `config` has been explicitly set.
    var hasConfig: Bool {return _storage._config != nil}
    /// Clears the value of `config`. Subsequent reads from it will return its default value.
    mutating func clearConfig() {_uniqueStorage()._config = nil}

    var photo: Arsdk_Camera_Event.State.Photo {
      get {return _storage._photo ?? Arsdk_Camera_Event.State.Photo()}
      set {_uniqueStorage()._photo = newValue}
    }
    /// Returns true if `photo` has been explicitly set.
    var hasPhoto: Bool {return _storage._photo != nil}
    /// Clears the value of `photo`. Subsequent reads from it will return its default value.
    mutating func clearPhoto() {_uniqueStorage()._photo = nil}

    var recording: Arsdk_Camera_Event.State.Recording {
      get {return _storage._recording ?? Arsdk_Camera_Event.State.Recording()}
      set {_uniqueStorage()._recording = newValue}
    }
    /// Returns true if `recording` has been explicitly set.
    var hasRecording: Bool {return _storage._recording != nil}
    /// Clears the value of `recording`. Subsequent reads from it will return its default value.
    mutating func clearRecording() {_uniqueStorage()._recording = nil}

    var whiteBalanceLock: Arsdk_Camera_Event.State.WhiteBalanceLock {
      get {return _storage._whiteBalanceLock ?? Arsdk_Camera_Event.State.WhiteBalanceLock()}
      set {_uniqueStorage()._whiteBalanceLock = newValue}
    }
    /// Returns true if `whiteBalanceLock` has been explicitly set.
    var hasWhiteBalanceLock: Bool {return _storage._whiteBalanceLock != nil}
    /// Clears the value of `whiteBalanceLock`. Subsequent reads from it will return its default value.
    mutating func clearWhiteBalanceLock() {_uniqueStorage()._whiteBalanceLock = nil}

    var exposureLock: Arsdk_Camera_Event.State.ExposureLock {
      get {return _storage._exposureLock ?? Arsdk_Camera_Event.State.ExposureLock()}
      set {_uniqueStorage()._exposureLock = newValue}
    }
    /// Returns true if `exposureLock` has been explicitly set.
    var hasExposureLock: Bool {return _storage._exposureLock != nil}
    /// Clears the value of `exposureLock`. Subsequent reads from it will return its default value.
    mutating func clearExposureLock() {_uniqueStorage()._exposureLock = nil}

    var zoom: Arsdk_Camera_Event.State.Zoom {
      get {return _storage._zoom ?? Arsdk_Camera_Event.State.Zoom()}
      set {_uniqueStorage()._zoom = newValue}
    }
    /// Returns true if `zoom` has been explicitly set.
    var hasZoom: Bool {return _storage._zoom != nil}
    /// Clears the value of `zoom`. Subsequent reads from it will return its default value.
    mutating func clearZoom() {_uniqueStorage()._zoom = nil}

    var mediaMetadata: Arsdk_Camera_MediaMetadata {
      get {return _storage._mediaMetadata ?? Arsdk_Camera_MediaMetadata()}
      set {_uniqueStorage()._mediaMetadata = newValue}
    }
    /// Returns true if `mediaMetadata` has been explicitly set.
    var hasMediaMetadata: Bool {return _storage._mediaMetadata != nil}
    /// Clears the value of `mediaMetadata`. Subsequent reads from it will return its default value.
    mutating func clearMediaMetadata() {_uniqueStorage()._mediaMetadata = nil}

    var unknownFields = SwiftProtobuf.UnknownStorage()

    struct Photo {
      // SwiftProtobuf.Message conformance is added in an extension below. See the
      // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
      // methods supported on all messages.

      var state: Arsdk_Camera_PhotoState = .unavailable

      var startTimestamp: UInt64 = 0

      var photoCount: UInt32 = 0

      var storage: Arsdk_Camera_StorageType = .internal

      var unknownFields = SwiftProtobuf.UnknownStorage()

      init() {}
    }

    struct Recording {
      // SwiftProtobuf.Message conformance is added in an extension below. See the
      // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
      // methods supported on all messages.

      var state: Arsdk_Camera_RecordingState = .unavailable

      var startTimestamp: UInt64 = 0

      var videoBitrate: UInt32 = 0

      var storage: Arsdk_Camera_StorageType = .internal

      var unknownFields = SwiftProtobuf.UnknownStorage()

      init() {}
    }

    struct WhiteBalanceLock {
      // SwiftProtobuf.Message conformance is added in an extension below. See the
      // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
      // methods supported on all messages.

      var supportedModes: [Arsdk_Camera_WhiteBalanceLockMode] = []

      var mode: Arsdk_Camera_WhiteBalanceLockMode = .unlocked

      var unknownFields = SwiftProtobuf.UnknownStorage()

      init() {}
    }

    struct ExposureLock {
      // SwiftProtobuf.Message conformance is added in an extension below. See the
      // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
      // methods supported on all messages.

      var supportedModes: [Arsdk_Camera_ExposureLockMode] = []

      var mode: Arsdk_Camera_ExposureLockMode = .unlocked

      var unknownFields = SwiftProtobuf.UnknownStorage()

      init() {}
    }

    struct Zoom {
      // SwiftProtobuf.Message conformance is added in an extension below. See the
      // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
      // methods supported on all messages.

      var zoomLevelMax: Double = 0

      var zoomHighQualityLevelMax: Double = 0

      var unknownFields = SwiftProtobuf.UnknownStorage()

      init() {}
    }

    init() {}

    fileprivate var _storage = _StorageClass.defaultInstance
  }

  struct Exposure {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var cameraID: UInt64 = 0

    var shutterSpeed: Arsdk_Camera_ShutterSpeed = .shutterSpeed1Over10000

    var isoSensitivity: Arsdk_Camera_IsoSensitivity = .isoSensitivity25

    var exposureLockRegion: Arsdk_Camera_ExposureRoi {
      get {return _exposureLockRegion ?? Arsdk_Camera_ExposureRoi()}
      set {_exposureLockRegion = newValue}
    }
    /// Returns true if `exposureLockRegion` has been explicitly set.
    var hasExposureLockRegion: Bool {return self._exposureLockRegion != nil}
    /// Clears the value of `exposureLockRegion`. Subsequent reads from it will return its default value.
    mutating func clearExposureLockRegion() {self._exposureLockRegion = nil}

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}

    fileprivate var _exposureLockRegion: Arsdk_Camera_ExposureRoi? = nil
  }

  struct ZoomLevel {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var cameraID: UInt64 = 0

    var level: Double = 0

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  struct NextPhotoInterval {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var cameraID: UInt64 = 0

    var mode: Arsdk_Camera_PhotoMode = .single

    var interval: Double = 0

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  struct Photo {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var cameraID: UInt64 = 0

    var type: Arsdk_Camera_PhotoEvent = .start

    var mediaID: String = String()

    var stopReason: Arsdk_Camera_PhotoStopReason = .userRequest

    var resourceID: String = String()

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  struct Recording {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var cameraID: UInt64 = 0

    var type: Arsdk_Camera_RecordingEvent = .start

    var mediaID: String = String()

    var stopReason: Arsdk_Camera_RecordingStopReason = .userRequest

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  init() {}
}

struct Arsdk_Camera_Capabilities {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  var rules: [Arsdk_Camera_Capabilities.Rule] = []

  var unknownFields = SwiftProtobuf.UnknownStorage()

  struct Rule {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var index: UInt64 {
      get {return _storage._index}
      set {_uniqueStorage()._index = newValue}
    }

    var selectedFields: Dictionary<UInt32,SwiftProtobuf.Google_Protobuf_Empty> {
      get {return _storage._selectedFields}
      set {_uniqueStorage()._selectedFields = newValue}
    }

    var cameraModes: [Arsdk_Camera_CameraMode] {
      get {return _storage._cameraModes}
      set {_uniqueStorage()._cameraModes = newValue}
    }

    var photoModes: [Arsdk_Camera_PhotoMode] {
      get {return _storage._photoModes}
      set {_uniqueStorage()._photoModes = newValue}
    }

    var photoDynamicRanges: [Arsdk_Camera_DynamicRange] {
      get {return _storage._photoDynamicRanges}
      set {_uniqueStorage()._photoDynamicRanges = newValue}
    }

    var photoResolutions: [Arsdk_Camera_PhotoResolution] {
      get {return _storage._photoResolutions}
      set {_uniqueStorage()._photoResolutions = newValue}
    }

    var photoFormats: [Arsdk_Camera_PhotoFormat] {
      get {return _storage._photoFormats}
      set {_uniqueStorage()._photoFormats = newValue}
    }

    var photoFileFormats: [Arsdk_Camera_PhotoFileFormat] {
      get {return _storage._photoFileFormats}
      set {_uniqueStorage()._photoFileFormats = newValue}
    }

    var photoBurstValues: [Arsdk_Camera_BurstValue] {
      get {return _storage._photoBurstValues}
      set {_uniqueStorage()._photoBurstValues = newValue}
    }

    var photoBracketingPresets: [Arsdk_Camera_BracketingPreset] {
      get {return _storage._photoBracketingPresets}
      set {_uniqueStorage()._photoBracketingPresets = newValue}
    }

    var photoTimeLapseIntervalRange: Arsdk_Camera_DoubleRange {
      get {return _storage._photoTimeLapseIntervalRange ?? Arsdk_Camera_DoubleRange()}
      set {_uniqueStorage()._photoTimeLapseIntervalRange = newValue}
    }
    /// Returns true if `photoTimeLapseIntervalRange` has been explicitly set.
    var hasPhotoTimeLapseIntervalRange: Bool {return _storage._photoTimeLapseIntervalRange != nil}
    /// Clears the value of `photoTimeLapseIntervalRange`. Subsequent reads from it will return its default value.
    mutating func clearPhotoTimeLapseIntervalRange() {_uniqueStorage()._photoTimeLapseIntervalRange = nil}

    var photoGpsLapseIntervalRange: Arsdk_Camera_DoubleRange {
      get {return _storage._photoGpsLapseIntervalRange ?? Arsdk_Camera_DoubleRange()}
      set {_uniqueStorage()._photoGpsLapseIntervalRange = newValue}
    }
    /// Returns true if `photoGpsLapseIntervalRange` has been explicitly set.
    var hasPhotoGpsLapseIntervalRange: Bool {return _storage._photoGpsLapseIntervalRange != nil}
    /// Clears the value of `photoGpsLapseIntervalRange`. Subsequent reads from it will return its default value.
    mutating func clearPhotoGpsLapseIntervalRange() {_uniqueStorage()._photoGpsLapseIntervalRange = nil}

    var photoStreamingModes: [Arsdk_Camera_PhotoStreamingMode] {
      get {return _storage._photoStreamingModes}
      set {_uniqueStorage()._photoStreamingModes = newValue}
    }

    var videoRecordingModes: [Arsdk_Camera_VideoRecordingMode] {
      get {return _storage._videoRecordingModes}
      set {_uniqueStorage()._videoRecordingModes = newValue}
    }

    var videoRecordingDynamicRanges: [Arsdk_Camera_DynamicRange] {
      get {return _storage._videoRecordingDynamicRanges}
      set {_uniqueStorage()._videoRecordingDynamicRanges = newValue}
    }

    var videoRecordingCodecs: [Arsdk_Camera_VideoCodec] {
      get {return _storage._videoRecordingCodecs}
      set {_uniqueStorage()._videoRecordingCodecs = newValue}
    }

    var videoRecordingResolutions: [Arsdk_Camera_VideoResolution] {
      get {return _storage._videoRecordingResolutions}
      set {_uniqueStorage()._videoRecordingResolutions = newValue}
    }

    var videoRecordingFramerates: [Arsdk_Camera_Framerate] {
      get {return _storage._videoRecordingFramerates}
      set {_uniqueStorage()._videoRecordingFramerates = newValue}
    }

    var audioRecordingModes: [Arsdk_Camera_AudioRecordingMode] {
      get {return _storage._audioRecordingModes}
      set {_uniqueStorage()._audioRecordingModes = newValue}
    }

    var exposureModes: [Arsdk_Camera_ExposureMode] {
      get {return _storage._exposureModes}
      set {_uniqueStorage()._exposureModes = newValue}
    }

    var exposureManualShutterSpeeds: [Arsdk_Camera_ShutterSpeed] {
      get {return _storage._exposureManualShutterSpeeds}
      set {_uniqueStorage()._exposureManualShutterSpeeds = newValue}
    }

    var exposureManualIsoSensitivities: [Arsdk_Camera_IsoSensitivity] {
      get {return _storage._exposureManualIsoSensitivities}
      set {_uniqueStorage()._exposureManualIsoSensitivities = newValue}
    }

    var exposureMaximumIsoSensitivities: [Arsdk_Camera_IsoSensitivity] {
      get {return _storage._exposureMaximumIsoSensitivities}
      set {_uniqueStorage()._exposureMaximumIsoSensitivities = newValue}
    }

    var whiteBalanceModes: [Arsdk_Camera_WhiteBalanceMode] {
      get {return _storage._whiteBalanceModes}
      set {_uniqueStorage()._whiteBalanceModes = newValue}
    }

    var whiteBalanceTemperatures: [Arsdk_Camera_WhiteBalanceTemperature] {
      get {return _storage._whiteBalanceTemperatures}
      set {_uniqueStorage()._whiteBalanceTemperatures = newValue}
    }

    var evCompensations: [Arsdk_Camera_EvCompensation] {
      get {return _storage._evCompensations}
      set {_uniqueStorage()._evCompensations = newValue}
    }

    var imageStyles: [Arsdk_Camera_ImageStyle] {
      get {return _storage._imageStyles}
      set {_uniqueStorage()._imageStyles = newValue}
    }

    var imageContrastRange: Arsdk_Camera_DoubleRange {
      get {return _storage._imageContrastRange ?? Arsdk_Camera_DoubleRange()}
      set {_uniqueStorage()._imageContrastRange = newValue}
    }
    /// Returns true if `imageContrastRange` has been explicitly set.
    var hasImageContrastRange: Bool {return _storage._imageContrastRange != nil}
    /// Clears the value of `imageContrastRange`. Subsequent reads from it will return its default value.
    mutating func clearImageContrastRange() {_uniqueStorage()._imageContrastRange = nil}

    var imageSaturationRange: Arsdk_Camera_DoubleRange {
      get {return _storage._imageSaturationRange ?? Arsdk_Camera_DoubleRange()}
      set {_uniqueStorage()._imageSaturationRange = newValue}
    }
    /// Returns true if `imageSaturationRange` has been explicitly set.
    var hasImageSaturationRange: Bool {return _storage._imageSaturationRange != nil}
    /// Clears the value of `imageSaturationRange`. Subsequent reads from it will return its default value.
    mutating func clearImageSaturationRange() {_uniqueStorage()._imageSaturationRange = nil}

    var imageSharpnessRange: Arsdk_Camera_DoubleRange {
      get {return _storage._imageSharpnessRange ?? Arsdk_Camera_DoubleRange()}
      set {_uniqueStorage()._imageSharpnessRange = newValue}
    }
    /// Returns true if `imageSharpnessRange` has been explicitly set.
    var hasImageSharpnessRange: Bool {return _storage._imageSharpnessRange != nil}
    /// Clears the value of `imageSharpnessRange`. Subsequent reads from it will return its default value.
    mutating func clearImageSharpnessRange() {_uniqueStorage()._imageSharpnessRange = nil}

    var zoomMaxSpeedRange: Arsdk_Camera_DoubleRange {
      get {return _storage._zoomMaxSpeedRange ?? Arsdk_Camera_DoubleRange()}
      set {_uniqueStorage()._zoomMaxSpeedRange = newValue}
    }
    /// Returns true if `zoomMaxSpeedRange` has been explicitly set.
    var hasZoomMaxSpeedRange: Bool {return _storage._zoomMaxSpeedRange != nil}
    /// Clears the value of `zoomMaxSpeedRange`. Subsequent reads from it will return its default value.
    mutating func clearZoomMaxSpeedRange() {_uniqueStorage()._zoomMaxSpeedRange = nil}

    var zoomVelocityControlQualityModes: [Arsdk_Camera_ZoomVelocityControlQualityMode] {
      get {return _storage._zoomVelocityControlQualityModes}
      set {_uniqueStorage()._zoomVelocityControlQualityModes = newValue}
    }

    var autoRecordModes: [Arsdk_Camera_AutoRecordMode] {
      get {return _storage._autoRecordModes}
      set {_uniqueStorage()._autoRecordModes = newValue}
    }

    var alignmentOffsetPitchRange: Arsdk_Camera_DoubleRange {
      get {return _storage._alignmentOffsetPitchRange ?? Arsdk_Camera_DoubleRange()}
      set {_uniqueStorage()._alignmentOffsetPitchRange = newValue}
    }
    /// Returns true if `alignmentOffsetPitchRange` has been explicitly set.
    var hasAlignmentOffsetPitchRange: Bool {return _storage._alignmentOffsetPitchRange != nil}
    /// Clears the value of `alignmentOffsetPitchRange`. Subsequent reads from it will return its default value.
    mutating func clearAlignmentOffsetPitchRange() {_uniqueStorage()._alignmentOffsetPitchRange = nil}

    var alignmentOffsetRollRange: Arsdk_Camera_DoubleRange {
      get {return _storage._alignmentOffsetRollRange ?? Arsdk_Camera_DoubleRange()}
      set {_uniqueStorage()._alignmentOffsetRollRange = newValue}
    }
    /// Returns true if `alignmentOffsetRollRange` has been explicitly set.
    var hasAlignmentOffsetRollRange: Bool {return _storage._alignmentOffsetRollRange != nil}
    /// Clears the value of `alignmentOffsetRollRange`. Subsequent reads from it will return its default value.
    mutating func clearAlignmentOffsetRollRange() {_uniqueStorage()._alignmentOffsetRollRange = nil}

    var alignmentOffsetYawRange: Arsdk_Camera_DoubleRange {
      get {return _storage._alignmentOffsetYawRange ?? Arsdk_Camera_DoubleRange()}
      set {_uniqueStorage()._alignmentOffsetYawRange = newValue}
    }
    /// Returns true if `alignmentOffsetYawRange` has been explicitly set.
    var hasAlignmentOffsetYawRange: Bool {return _storage._alignmentOffsetYawRange != nil}
    /// Clears the value of `alignmentOffsetYawRange`. Subsequent reads from it will return its default value.
    mutating func clearAlignmentOffsetYawRange() {_uniqueStorage()._alignmentOffsetYawRange = nil}

    var photoSignatures: [Arsdk_Camera_DigitalSignature] {
      get {return _storage._photoSignatures}
      set {_uniqueStorage()._photoSignatures = newValue}
    }

    var exposureMeterings: [Arsdk_Camera_ExposureMetering] {
      get {return _storage._exposureMeterings}
      set {_uniqueStorage()._exposureMeterings = newValue}
    }

    var storagePolicies: [Arsdk_Camera_StoragePolicy] {
      get {return _storage._storagePolicies}
      set {_uniqueStorage()._storagePolicies = newValue}
    }

    var videoRecordingBitrates: [UInt32] {
      get {return _storage._videoRecordingBitrates}
      set {_uniqueStorage()._videoRecordingBitrates = newValue}
    }

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}

    fileprivate var _storage = _StorageClass.defaultInstance
  }

  init() {}
}

struct Arsdk_Camera_Config {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  var selectedFields: Dictionary<UInt32,SwiftProtobuf.Google_Protobuf_Empty> {
    get {return _storage._selectedFields}
    set {_uniqueStorage()._selectedFields = newValue}
  }

  var cameraMode: Arsdk_Camera_CameraMode {
    get {return _storage._cameraMode}
    set {_uniqueStorage()._cameraMode = newValue}
  }

  var photoMode: Arsdk_Camera_PhotoMode {
    get {return _storage._photoMode}
    set {_uniqueStorage()._photoMode = newValue}
  }

  var photoDynamicRange: Arsdk_Camera_DynamicRange {
    get {return _storage._photoDynamicRange}
    set {_uniqueStorage()._photoDynamicRange = newValue}
  }

  var photoResolution: Arsdk_Camera_PhotoResolution {
    get {return _storage._photoResolution}
    set {_uniqueStorage()._photoResolution = newValue}
  }

  var photoFormat: Arsdk_Camera_PhotoFormat {
    get {return _storage._photoFormat}
    set {_uniqueStorage()._photoFormat = newValue}
  }

  var photoFileFormat: Arsdk_Camera_PhotoFileFormat {
    get {return _storage._photoFileFormat}
    set {_uniqueStorage()._photoFileFormat = newValue}
  }

  var photoBurstValue: Arsdk_Camera_BurstValue {
    get {return _storage._photoBurstValue}
    set {_uniqueStorage()._photoBurstValue = newValue}
  }

  var photoBracketingPreset: Arsdk_Camera_BracketingPreset {
    get {return _storage._photoBracketingPreset}
    set {_uniqueStorage()._photoBracketingPreset = newValue}
  }

  var photoTimeLapseInterval: Double {
    get {return _storage._photoTimeLapseInterval}
    set {_uniqueStorage()._photoTimeLapseInterval = newValue}
  }

  var photoGpsLapseInterval: Double {
    get {return _storage._photoGpsLapseInterval}
    set {_uniqueStorage()._photoGpsLapseInterval = newValue}
  }

  var photoStreamingMode: Arsdk_Camera_PhotoStreamingMode {
    get {return _storage._photoStreamingMode}
    set {_uniqueStorage()._photoStreamingMode = newValue}
  }

  var videoRecordingMode: Arsdk_Camera_VideoRecordingMode {
    get {return _storage._videoRecordingMode}
    set {_uniqueStorage()._videoRecordingMode = newValue}
  }

  var videoRecordingDynamicRange: Arsdk_Camera_DynamicRange {
    get {return _storage._videoRecordingDynamicRange}
    set {_uniqueStorage()._videoRecordingDynamicRange = newValue}
  }

  var videoRecordingCodec: Arsdk_Camera_VideoCodec {
    get {return _storage._videoRecordingCodec}
    set {_uniqueStorage()._videoRecordingCodec = newValue}
  }

  var videoRecordingResolution: Arsdk_Camera_VideoResolution {
    get {return _storage._videoRecordingResolution}
    set {_uniqueStorage()._videoRecordingResolution = newValue}
  }

  var videoRecordingFramerate: Arsdk_Camera_Framerate {
    get {return _storage._videoRecordingFramerate}
    set {_uniqueStorage()._videoRecordingFramerate = newValue}
  }

  var audioRecordingMode: Arsdk_Camera_AudioRecordingMode {
    get {return _storage._audioRecordingMode}
    set {_uniqueStorage()._audioRecordingMode = newValue}
  }

  var exposureMode: Arsdk_Camera_ExposureMode {
    get {return _storage._exposureMode}
    set {_uniqueStorage()._exposureMode = newValue}
  }

  var exposureManualShutterSpeed: Arsdk_Camera_ShutterSpeed {
    get {return _storage._exposureManualShutterSpeed}
    set {_uniqueStorage()._exposureManualShutterSpeed = newValue}
  }

  var exposureManualIsoSensitivity: Arsdk_Camera_IsoSensitivity {
    get {return _storage._exposureManualIsoSensitivity}
    set {_uniqueStorage()._exposureManualIsoSensitivity = newValue}
  }

  var exposureMaximumIsoSensitivity: Arsdk_Camera_IsoSensitivity {
    get {return _storage._exposureMaximumIsoSensitivity}
    set {_uniqueStorage()._exposureMaximumIsoSensitivity = newValue}
  }

  var whiteBalanceMode: Arsdk_Camera_WhiteBalanceMode {
    get {return _storage._whiteBalanceMode}
    set {_uniqueStorage()._whiteBalanceMode = newValue}
  }

  var whiteBalanceTemperature: Arsdk_Camera_WhiteBalanceTemperature {
    get {return _storage._whiteBalanceTemperature}
    set {_uniqueStorage()._whiteBalanceTemperature = newValue}
  }

  var evCompensation: Arsdk_Camera_EvCompensation {
    get {return _storage._evCompensation}
    set {_uniqueStorage()._evCompensation = newValue}
  }

  var imageStyle: Arsdk_Camera_ImageStyle {
    get {return _storage._imageStyle}
    set {_uniqueStorage()._imageStyle = newValue}
  }

  var imageContrast: Double {
    get {return _storage._imageContrast}
    set {_uniqueStorage()._imageContrast = newValue}
  }

  var imageSaturation: Double {
    get {return _storage._imageSaturation}
    set {_uniqueStorage()._imageSaturation = newValue}
  }

  var imageSharpness: Double {
    get {return _storage._imageSharpness}
    set {_uniqueStorage()._imageSharpness = newValue}
  }

  var zoomMaxSpeed: Double {
    get {return _storage._zoomMaxSpeed}
    set {_uniqueStorage()._zoomMaxSpeed = newValue}
  }

  var zoomVelocityControlQualityMode: Arsdk_Camera_ZoomVelocityControlQualityMode {
    get {return _storage._zoomVelocityControlQualityMode}
    set {_uniqueStorage()._zoomVelocityControlQualityMode = newValue}
  }

  var autoRecordMode: Arsdk_Camera_AutoRecordMode {
    get {return _storage._autoRecordMode}
    set {_uniqueStorage()._autoRecordMode = newValue}
  }

  var alignmentOffsetPitch: Double {
    get {return _storage._alignmentOffsetPitch}
    set {_uniqueStorage()._alignmentOffsetPitch = newValue}
  }

  var alignmentOffsetRoll: Double {
    get {return _storage._alignmentOffsetRoll}
    set {_uniqueStorage()._alignmentOffsetRoll = newValue}
  }

  var alignmentOffsetYaw: Double {
    get {return _storage._alignmentOffsetYaw}
    set {_uniqueStorage()._alignmentOffsetYaw = newValue}
  }

  var photoSignature: Arsdk_Camera_DigitalSignature {
    get {return _storage._photoSignature}
    set {_uniqueStorage()._photoSignature = newValue}
  }

  var exposureMetering: Arsdk_Camera_ExposureMetering {
    get {return _storage._exposureMetering}
    set {_uniqueStorage()._exposureMetering = newValue}
  }

  var storagePolicy: Arsdk_Camera_StoragePolicy {
    get {return _storage._storagePolicy}
    set {_uniqueStorage()._storagePolicy = newValue}
  }

  var videoRecordingBitrate: UInt32 {
    get {return _storage._videoRecordingBitrate}
    set {_uniqueStorage()._videoRecordingBitrate = newValue}
  }

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

struct Arsdk_Camera_DoubleRange {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  var min: Double = 0

  var max: Double = 0

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}
}

struct Arsdk_Camera_ExposureRoi {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  var center: Arsdk_Camera_ExposureRoi.Center {
    get {return _center ?? Arsdk_Camera_ExposureRoi.Center()}
    set {_center = newValue}
  }
  /// Returns true if `center` has been explicitly set.
  var hasCenter: Bool {return self._center != nil}
  /// Clears the value of `center`. Subsequent reads from it will return its default value.
  mutating func clearCenter() {self._center = nil}

  var width: Double = 0

  var height: Double = 0

  var unknownFields = SwiftProtobuf.UnknownStorage()

  struct Center {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var x: Double = 0

    var y: Double = 0

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  init() {}

  fileprivate var _center: Arsdk_Camera_ExposureRoi.Center? = nil
}

struct Arsdk_Camera_MediaMetadata {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  var selectedFields: Dictionary<UInt32,SwiftProtobuf.Google_Protobuf_Empty> = [:]

  var copyright: String = String()

  var customID: String = String()

  var customTitle: String = String()

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}
}

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "arsdk.camera"

extension Arsdk_Camera_AudioRecordingMode: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "AUDIO_RECORDING_MODE_MUTE"),
    1: .same(proto: "AUDIO_RECORDING_MODE_DRONE"),
  ]
}

extension Arsdk_Camera_AutoRecordMode: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "AUTO_RECORD_MODE_DISABLED"),
    1: .same(proto: "AUTO_RECORD_MODE_FLIGHT"),
  ]
}

extension Arsdk_Camera_BracketingPreset: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "BRACKETING_PRESET_1EV"),
    1: .same(proto: "BRACKETING_PRESET_2EV"),
    2: .same(proto: "BRACKETING_PRESET_3EV"),
    3: .same(proto: "BRACKETING_PRESET_1EV_2EV"),
    4: .same(proto: "BRACKETING_PRESET_1EV_3EV"),
    5: .same(proto: "BRACKETING_PRESET_2EV_3EV"),
    6: .same(proto: "BRACKETING_PRESET_1EV_2EV_3EV"),
  ]
}

extension Arsdk_Camera_BurstValue: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "BURST_VALUE_14_OVER_4S"),
    1: .same(proto: "BURST_VALUE_14_OVER_2S"),
    2: .same(proto: "BURST_VALUE_14_OVER_1S"),
    3: .same(proto: "BURST_VALUE_10_OVER_4S"),
    4: .same(proto: "BURST_VALUE_10_OVER_2S"),
    5: .same(proto: "BURST_VALUE_10_OVER_1S"),
    6: .same(proto: "BURST_VALUE_4_OVER_4S"),
    7: .same(proto: "BURST_VALUE_4_OVER_2S"),
    8: .same(proto: "BURST_VALUE_4_OVER_1S"),
  ]
}

extension Arsdk_Camera_CameraMode: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "CAMERA_MODE_PHOTO"),
    1: .same(proto: "CAMERA_MODE_RECORDING"),
  ]
}

extension Arsdk_Camera_CameraModel: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "CAMERA_MODEL_MAIN"),
  ]
}

extension Arsdk_Camera_DigitalSignature: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "DIGITAL_SIGNATURE_NONE"),
    1: .same(proto: "DIGITAL_SIGNATURE_DRONE"),
  ]
}

extension Arsdk_Camera_DynamicRange: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "DYNAMIC_RANGE_STANDARD"),
    1: .same(proto: "DYNAMIC_RANGE_HDR8"),
    2: .same(proto: "DYNAMIC_RANGE_HDR10"),
  ]
}

extension Arsdk_Camera_EvCompensation: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "EV_COMPENSATION_MINUS_3_00"),
    1: .same(proto: "EV_COMPENSATION_MINUS_2_67"),
    2: .same(proto: "EV_COMPENSATION_MINUS_2_33"),
    3: .same(proto: "EV_COMPENSATION_MINUS_2_00"),
    4: .same(proto: "EV_COMPENSATION_MINUS_1_67"),
    5: .same(proto: "EV_COMPENSATION_MINUS_1_33"),
    6: .same(proto: "EV_COMPENSATION_MINUS_1_00"),
    7: .same(proto: "EV_COMPENSATION_MINUS_0_67"),
    8: .same(proto: "EV_COMPENSATION_MINUS_0_33"),
    9: .same(proto: "EV_COMPENSATION_0_00"),
    10: .same(proto: "EV_COMPENSATION_0_33"),
    11: .same(proto: "EV_COMPENSATION_0_67"),
    12: .same(proto: "EV_COMPENSATION_1_00"),
    13: .same(proto: "EV_COMPENSATION_1_33"),
    14: .same(proto: "EV_COMPENSATION_1_67"),
    15: .same(proto: "EV_COMPENSATION_2_00"),
    16: .same(proto: "EV_COMPENSATION_2_33"),
    17: .same(proto: "EV_COMPENSATION_2_67"),
    18: .same(proto: "EV_COMPENSATION_3_00"),
  ]
}

extension Arsdk_Camera_ExposureLockMode: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "EXPOSURE_LOCK_MODE_UNLOCKED"),
    1: .same(proto: "EXPOSURE_LOCK_MODE_FULL_LOCK"),
    2: .same(proto: "EXPOSURE_LOCK_MODE_ROI_LOCK"),
  ]
}

extension Arsdk_Camera_ExposureMetering: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "EXPOSURE_METERING_STANDARD"),
    1: .same(proto: "EXPOSURE_METERING_CENTER_TOP"),
  ]
}

extension Arsdk_Camera_ExposureMode: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "EXPOSURE_MODE_AUTOMATIC"),
    1: .same(proto: "EXPOSURE_MODE_AUTOMATIC_PREFER_ISO_SENSITIVITY"),
    2: .same(proto: "EXPOSURE_MODE_AUTOMATIC_PREFER_SHUTTER_SPEED"),
    3: .same(proto: "EXPOSURE_MODE_MANUAL_ISO_SENSITIVITY"),
    4: .same(proto: "EXPOSURE_MODE_MANUAL_SHUTTER_SPEED"),
    5: .same(proto: "EXPOSURE_MODE_MANUAL"),
  ]
}

extension Arsdk_Camera_Framerate: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "FRAMERATE_24"),
    1: .same(proto: "FRAMERATE_25"),
    2: .same(proto: "FRAMERATE_30"),
    3: .same(proto: "FRAMERATE_48"),
    4: .same(proto: "FRAMERATE_50"),
    5: .same(proto: "FRAMERATE_60"),
    6: .same(proto: "FRAMERATE_96"),
    7: .same(proto: "FRAMERATE_100"),
    8: .same(proto: "FRAMERATE_120"),
  ]
}

extension Arsdk_Camera_ImageStyle: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "IMAGE_STYLE_CUSTOM"),
    1: .same(proto: "IMAGE_STYLE_STANDARD"),
    2: .same(proto: "IMAGE_STYLE_PLOG"),
    3: .same(proto: "IMAGE_STYLE_INTENSE"),
    4: .same(proto: "IMAGE_STYLE_PASTEL"),
    5: .same(proto: "IMAGE_STYLE_PHOTOGRAMMETRY"),
  ]
}

extension Arsdk_Camera_IsoSensitivity: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "ISO_SENSITIVITY_25"),
    1: .same(proto: "ISO_SENSITIVITY_50"),
    2: .same(proto: "ISO_SENSITIVITY_64"),
    3: .same(proto: "ISO_SENSITIVITY_80"),
    4: .same(proto: "ISO_SENSITIVITY_100"),
    5: .same(proto: "ISO_SENSITIVITY_125"),
    6: .same(proto: "ISO_SENSITIVITY_160"),
    7: .same(proto: "ISO_SENSITIVITY_200"),
    8: .same(proto: "ISO_SENSITIVITY_250"),
    9: .same(proto: "ISO_SENSITIVITY_320"),
    10: .same(proto: "ISO_SENSITIVITY_400"),
    11: .same(proto: "ISO_SENSITIVITY_500"),
    12: .same(proto: "ISO_SENSITIVITY_640"),
    13: .same(proto: "ISO_SENSITIVITY_800"),
    14: .same(proto: "ISO_SENSITIVITY_1000"),
    15: .same(proto: "ISO_SENSITIVITY_1200"),
    16: .same(proto: "ISO_SENSITIVITY_1600"),
    17: .same(proto: "ISO_SENSITIVITY_2000"),
    18: .same(proto: "ISO_SENSITIVITY_2500"),
    19: .same(proto: "ISO_SENSITIVITY_3200"),
    20: .same(proto: "ISO_SENSITIVITY_4000"),
    21: .same(proto: "ISO_SENSITIVITY_5000"),
    22: .same(proto: "ISO_SENSITIVITY_6400"),
    23: .same(proto: "ISO_SENSITIVITY_8000"),
    24: .same(proto: "ISO_SENSITIVITY_10000"),
    25: .same(proto: "ISO_SENSITIVITY_12800"),
    26: .same(proto: "ISO_SENSITIVITY_16000"),
    27: .same(proto: "ISO_SENSITIVITY_20000"),
    28: .same(proto: "ISO_SENSITIVITY_25600"),
    29: .same(proto: "ISO_SENSITIVITY_32000"),
    30: .same(proto: "ISO_SENSITIVITY_40000"),
    31: .same(proto: "ISO_SENSITIVITY_51200"),
  ]
}

extension Arsdk_Camera_PhotoState: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "PHOTO_STATE_UNAVAILABLE"),
    1: .same(proto: "PHOTO_STATE_INACTIVE"),
    2: .same(proto: "PHOTO_STATE_ACTIVE"),
  ]
}

extension Arsdk_Camera_PhotoEvent: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "PHOTO_EVENT_START"),
    1: .same(proto: "PHOTO_EVENT_TAKING_PHOTO"),
    4: .same(proto: "PHOTO_EVENT_STOP"),
  ]
}

extension Arsdk_Camera_PhotoFileFormat: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "PHOTO_FILE_FORMAT_JPEG"),
    2: .same(proto: "PHOTO_FILE_FORMAT_DNG_JPEG"),
  ]
}

extension Arsdk_Camera_PhotoFormat: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "PHOTO_FORMAT_FULL_FRAME"),
    1: .same(proto: "PHOTO_FORMAT_RECTILINEAR"),
    2: .same(proto: "PHOTO_FORMAT_FULL_FRAME_STABILIZED"),
  ]
}

extension Arsdk_Camera_PhotoMode: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "PHOTO_MODE_SINGLE"),
    1: .same(proto: "PHOTO_MODE_BRACKETING"),
    2: .same(proto: "PHOTO_MODE_BURST"),
    3: .same(proto: "PHOTO_MODE_TIME_LAPSE"),
    4: .same(proto: "PHOTO_MODE_GPS_LAPSE"),
  ]
}

extension Arsdk_Camera_PhotoResolution: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "PHOTO_RESOLUTION_48_MEGA_PIXELS"),
    2: .same(proto: "PHOTO_RESOLUTION_12_MEGA_PIXELS"),
  ]
}

extension Arsdk_Camera_PhotoStopReason: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "PHOTO_STOP_REASON_USER_REQUEST"),
    1: .same(proto: "PHOTO_STOP_REASON_CAPTURE_DONE"),
    2: .same(proto: "PHOTO_STOP_REASON_CONFIGURATION_CHANGE"),
    3: .same(proto: "PHOTO_STOP_REASON_INTERNAL_ERROR"),
    4: .same(proto: "PHOTO_STOP_REASON_INSUFFICIENT_STORAGE_SPACE"),
  ]
}

extension Arsdk_Camera_PhotoStreamingMode: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "PHOTO_STREAMING_MODE_INTERRUPT"),
    1: .same(proto: "PHOTO_STREAMING_MODE_CONTINUOUS"),
  ]
}

extension Arsdk_Camera_RecordingEvent: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "RECORDING_EVENT_START"),
    1: .same(proto: "RECORDING_EVENT_STOP"),
    2: .same(proto: "RECORDING_EVENT_STOPPING"),
  ]
}

extension Arsdk_Camera_RecordingState: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "RECORDING_STATE_UNAVAILABLE"),
    1: .same(proto: "RECORDING_STATE_INACTIVE"),
    3: .same(proto: "RECORDING_STATE_ACTIVE"),
  ]
}

extension Arsdk_Camera_RecordingStopReason: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "RECORDING_STOP_REASON_USER_REQUEST"),
    2: .same(proto: "RECORDING_STOP_REASON_CONFIGURATION_CHANGE"),
    3: .same(proto: "RECORDING_STOP_REASON_INTERNAL_ERROR"),
    4: .same(proto: "RECORDING_STOP_REASON_INSUFFICIENT_STORAGE_SPACE"),
    5: .same(proto: "RECORDING_STOP_REASON_INSUFFICIENT_STORAGE_SPEED"),
  ]
}

extension Arsdk_Camera_VideoRecordingMode: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "VIDEO_RECORDING_MODE_STANDARD"),
  ]
}

extension Arsdk_Camera_ShutterSpeed: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "SHUTTER_SPEED_1_OVER_10000"),
    1: .same(proto: "SHUTTER_SPEED_1_OVER_8000"),
    2: .same(proto: "SHUTTER_SPEED_1_OVER_6400"),
    3: .same(proto: "SHUTTER_SPEED_1_OVER_5000"),
    4: .same(proto: "SHUTTER_SPEED_1_OVER_4000"),
    5: .same(proto: "SHUTTER_SPEED_1_OVER_3200"),
    6: .same(proto: "SHUTTER_SPEED_1_OVER_2500"),
    7: .same(proto: "SHUTTER_SPEED_1_OVER_2000"),
    8: .same(proto: "SHUTTER_SPEED_1_OVER_1600"),
    9: .same(proto: "SHUTTER_SPEED_1_OVER_1250"),
    10: .same(proto: "SHUTTER_SPEED_1_OVER_1000"),
    11: .same(proto: "SHUTTER_SPEED_1_OVER_800"),
    12: .same(proto: "SHUTTER_SPEED_1_OVER_640"),
    13: .same(proto: "SHUTTER_SPEED_1_OVER_500"),
    14: .same(proto: "SHUTTER_SPEED_1_OVER_400"),
    15: .same(proto: "SHUTTER_SPEED_1_OVER_320"),
    16: .same(proto: "SHUTTER_SPEED_1_OVER_240"),
    17: .same(proto: "SHUTTER_SPEED_1_OVER_200"),
    18: .same(proto: "SHUTTER_SPEED_1_OVER_160"),
    19: .same(proto: "SHUTTER_SPEED_1_OVER_120"),
    20: .same(proto: "SHUTTER_SPEED_1_OVER_100"),
    21: .same(proto: "SHUTTER_SPEED_1_OVER_80"),
    22: .same(proto: "SHUTTER_SPEED_1_OVER_60"),
    23: .same(proto: "SHUTTER_SPEED_1_OVER_50"),
    24: .same(proto: "SHUTTER_SPEED_1_OVER_40"),
    25: .same(proto: "SHUTTER_SPEED_1_OVER_30"),
    26: .same(proto: "SHUTTER_SPEED_1_OVER_25"),
    27: .same(proto: "SHUTTER_SPEED_1_OVER_15"),
    28: .same(proto: "SHUTTER_SPEED_1_OVER_10"),
    29: .same(proto: "SHUTTER_SPEED_1_OVER_8"),
    30: .same(proto: "SHUTTER_SPEED_1_OVER_6"),
    31: .same(proto: "SHUTTER_SPEED_1_OVER_4"),
    32: .same(proto: "SHUTTER_SPEED_1_OVER_3"),
    33: .same(proto: "SHUTTER_SPEED_1_OVER_2"),
    34: .same(proto: "SHUTTER_SPEED_1_OVER_1_POINT_5"),
    35: .same(proto: "SHUTTER_SPEED_1"),
  ]
}

extension Arsdk_Camera_StoragePolicy: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "STORAGE_POLICY_AUTO"),
    1: .same(proto: "STORAGE_POLICY_INTERNAL"),
    2: .same(proto: "STORAGE_POLICY_REMOVABLE"),
  ]
}

extension Arsdk_Camera_StorageType: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "STORAGE_TYPE_INTERNAL"),
    1: .same(proto: "STORAGE_TYPE_REMOVABLE"),
  ]
}

extension Arsdk_Camera_VideoCodec: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "VIDEO_CODEC_H264"),
    1: .same(proto: "VIDEO_CODEC_H265"),
  ]
}

extension Arsdk_Camera_VideoResolution: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "VIDEO_RESOLUTION_RESERVED"),
    1: .same(proto: "VIDEO_RESOLUTION_2160P"),
    3: .same(proto: "VIDEO_RESOLUTION_1080P"),
  ]
}

extension Arsdk_Camera_WhiteBalanceLockMode: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "WHITE_BALANCE_LOCK_MODE_UNLOCKED"),
    1: .same(proto: "WHITE_BALANCE_LOCK_MODE_LOCKED"),
  ]
}

extension Arsdk_Camera_WhiteBalanceMode: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "WHITE_BALANCE_MODE_CUSTOM"),
    1: .same(proto: "WHITE_BALANCE_MODE_AUTOMATIC"),
    2: .same(proto: "WHITE_BALANCE_MODE_CANDLE"),
    3: .same(proto: "WHITE_BALANCE_MODE_SUNSET"),
    4: .same(proto: "WHITE_BALANCE_MODE_INCANDESCENT"),
    5: .same(proto: "WHITE_BALANCE_MODE_WARM_WHITE_FLUORESCENT"),
    6: .same(proto: "WHITE_BALANCE_MODE_HALOGEN"),
    7: .same(proto: "WHITE_BALANCE_MODE_FLUORESCENT"),
    8: .same(proto: "WHITE_BALANCE_MODE_COOL_WHITE_FLUORESCENT"),
    9: .same(proto: "WHITE_BALANCE_MODE_FLASH"),
    10: .same(proto: "WHITE_BALANCE_MODE_DAYLIGHT"),
    11: .same(proto: "WHITE_BALANCE_MODE_SUNNY"),
    12: .same(proto: "WHITE_BALANCE_MODE_CLOUDY"),
    13: .same(proto: "WHITE_BALANCE_MODE_SNOW"),
    14: .same(proto: "WHITE_BALANCE_MODE_HAZY"),
    15: .same(proto: "WHITE_BALANCE_MODE_SHADED"),
    16: .same(proto: "WHITE_BALANCE_MODE_GREEN_FOLIAGE"),
    17: .same(proto: "WHITE_BALANCE_MODE_BLUE_SKY"),
  ]
}

extension Arsdk_Camera_WhiteBalanceTemperature: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "WHITE_BALANCE_TEMPERATURE_1500"),
    1: .same(proto: "WHITE_BALANCE_TEMPERATURE_1750"),
    2: .same(proto: "WHITE_BALANCE_TEMPERATURE_2000"),
    3: .same(proto: "WHITE_BALANCE_TEMPERATURE_2250"),
    4: .same(proto: "WHITE_BALANCE_TEMPERATURE_2500"),
    5: .same(proto: "WHITE_BALANCE_TEMPERATURE_2750"),
    6: .same(proto: "WHITE_BALANCE_TEMPERATURE_3000"),
    7: .same(proto: "WHITE_BALANCE_TEMPERATURE_3250"),
    8: .same(proto: "WHITE_BALANCE_TEMPERATURE_3500"),
    9: .same(proto: "WHITE_BALANCE_TEMPERATURE_3750"),
    10: .same(proto: "WHITE_BALANCE_TEMPERATURE_4000"),
    11: .same(proto: "WHITE_BALANCE_TEMPERATURE_4250"),
    12: .same(proto: "WHITE_BALANCE_TEMPERATURE_4500"),
    13: .same(proto: "WHITE_BALANCE_TEMPERATURE_4750"),
    14: .same(proto: "WHITE_BALANCE_TEMPERATURE_5000"),
    15: .same(proto: "WHITE_BALANCE_TEMPERATURE_5250"),
    16: .same(proto: "WHITE_BALANCE_TEMPERATURE_5500"),
    17: .same(proto: "WHITE_BALANCE_TEMPERATURE_5750"),
    18: .same(proto: "WHITE_BALANCE_TEMPERATURE_6000"),
    19: .same(proto: "WHITE_BALANCE_TEMPERATURE_6250"),
    20: .same(proto: "WHITE_BALANCE_TEMPERATURE_6500"),
    21: .same(proto: "WHITE_BALANCE_TEMPERATURE_6750"),
    22: .same(proto: "WHITE_BALANCE_TEMPERATURE_7000"),
    23: .same(proto: "WHITE_BALANCE_TEMPERATURE_7250"),
    24: .same(proto: "WHITE_BALANCE_TEMPERATURE_7500"),
    25: .same(proto: "WHITE_BALANCE_TEMPERATURE_7750"),
    26: .same(proto: "WHITE_BALANCE_TEMPERATURE_8000"),
    27: .same(proto: "WHITE_BALANCE_TEMPERATURE_8250"),
    28: .same(proto: "WHITE_BALANCE_TEMPERATURE_8500"),
    29: .same(proto: "WHITE_BALANCE_TEMPERATURE_8750"),
    30: .same(proto: "WHITE_BALANCE_TEMPERATURE_9000"),
    31: .same(proto: "WHITE_BALANCE_TEMPERATURE_9250"),
    32: .same(proto: "WHITE_BALANCE_TEMPERATURE_9500"),
    33: .same(proto: "WHITE_BALANCE_TEMPERATURE_9750"),
    34: .same(proto: "WHITE_BALANCE_TEMPERATURE_10000"),
    35: .same(proto: "WHITE_BALANCE_TEMPERATURE_10250"),
    36: .same(proto: "WHITE_BALANCE_TEMPERATURE_10500"),
    37: .same(proto: "WHITE_BALANCE_TEMPERATURE_10750"),
    38: .same(proto: "WHITE_BALANCE_TEMPERATURE_11000"),
    39: .same(proto: "WHITE_BALANCE_TEMPERATURE_11250"),
    40: .same(proto: "WHITE_BALANCE_TEMPERATURE_11500"),
    41: .same(proto: "WHITE_BALANCE_TEMPERATURE_11750"),
    42: .same(proto: "WHITE_BALANCE_TEMPERATURE_12000"),
    43: .same(proto: "WHITE_BALANCE_TEMPERATURE_12250"),
    44: .same(proto: "WHITE_BALANCE_TEMPERATURE_12500"),
    45: .same(proto: "WHITE_BALANCE_TEMPERATURE_12750"),
    46: .same(proto: "WHITE_BALANCE_TEMPERATURE_13000"),
    47: .same(proto: "WHITE_BALANCE_TEMPERATURE_13250"),
    48: .same(proto: "WHITE_BALANCE_TEMPERATURE_13500"),
    49: .same(proto: "WHITE_BALANCE_TEMPERATURE_13750"),
    50: .same(proto: "WHITE_BALANCE_TEMPERATURE_14000"),
    51: .same(proto: "WHITE_BALANCE_TEMPERATURE_14250"),
    52: .same(proto: "WHITE_BALANCE_TEMPERATURE_14500"),
    53: .same(proto: "WHITE_BALANCE_TEMPERATURE_14750"),
    54: .same(proto: "WHITE_BALANCE_TEMPERATURE_15000"),
  ]
}

extension Arsdk_Camera_ZoomControlMode: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "ZOOM_CONTROL_MODE_LEVEL"),
    1: .same(proto: "ZOOM_CONTROL_MODE_VELOCITY"),
  ]
}

extension Arsdk_Camera_ZoomVelocityControlQualityMode: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "ZOOM_VELOCITY_CONTROL_QUALITY_MODE_ALLOW_DEGRADATION"),
    1: .same(proto: "ZOOM_VELOCITY_CONTROL_QUALITY_MODE_STOP_BEFORE_DEGRADATION"),
  ]
}

extension Arsdk_Camera_Command: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".Command"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "set_zoom_target"),
    16: .standard(proto: "list_cameras"),
    17: .standard(proto: "get_state"),
    18: .same(proto: "configure"),
    19: .standard(proto: "start_photo"),
    20: .standard(proto: "stop_photo"),
    21: .standard(proto: "start_recording"),
    22: .standard(proto: "stop_recording"),
    23: .standard(proto: "lock_exposure"),
    24: .standard(proto: "lock_white_balance"),
    25: .standard(proto: "set_media_metadata"),
    26: .standard(proto: "reset_zoom"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Arsdk_Camera_Command.SetZoomTarget?
        var hadOneofValue = false
        if let current = self.id {
          hadOneofValue = true
          if case .setZoomTarget(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.id = .setZoomTarget(v)
        }
      }()
      case 16: try {
        var v: Arsdk_Camera_Command.ListCameras?
        var hadOneofValue = false
        if let current = self.id {
          hadOneofValue = true
          if case .listCameras(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.id = .listCameras(v)
        }
      }()
      case 17: try {
        var v: Arsdk_Camera_Command.GetState?
        var hadOneofValue = false
        if let current = self.id {
          hadOneofValue = true
          if case .getState(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.id = .getState(v)
        }
      }()
      case 18: try {
        var v: Arsdk_Camera_Command.Configure?
        var hadOneofValue = false
        if let current = self.id {
          hadOneofValue = true
          if case .configure(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.id = .configure(v)
        }
      }()
      case 19: try {
        var v: Arsdk_Camera_Command.StartPhoto?
        var hadOneofValue = false
        if let current = self.id {
          hadOneofValue = true
          if case .startPhoto(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.id = .startPhoto(v)
        }
      }()
      case 20: try {
        var v: Arsdk_Camera_Command.StopPhoto?
        var hadOneofValue = false
        if let current = self.id {
          hadOneofValue = true
          if case .stopPhoto(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.id = .stopPhoto(v)
        }
      }()
      case 21: try {
        var v: Arsdk_Camera_Command.StartRecording?
        var hadOneofValue = false
        if let current = self.id {
          hadOneofValue = true
          if case .startRecording(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.id = .startRecording(v)
        }
      }()
      case 22: try {
        var v: Arsdk_Camera_Command.StopRecording?
        var hadOneofValue = false
        if let current = self.id {
          hadOneofValue = true
          if case .stopRecording(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.id = .stopRecording(v)
        }
      }()
      case 23: try {
        var v: Arsdk_Camera_Command.LockExposure?
        var hadOneofValue = false
        if let current = self.id {
          hadOneofValue = true
          if case .lockExposure(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.id = .lockExposure(v)
        }
      }()
      case 24: try {
        var v: Arsdk_Camera_Command.LockWhiteBalance?
        var hadOneofValue = false
        if let current = self.id {
          hadOneofValue = true
          if case .lockWhiteBalance(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.id = .lockWhiteBalance(v)
        }
      }()
      case 25: try {
        var v: Arsdk_Camera_Command.SetMediaMetadata?
        var hadOneofValue = false
        if let current = self.id {
          hadOneofValue = true
          if case .setMediaMetadata(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.id = .setMediaMetadata(v)
        }
      }()
      case 26: try {
        var v: Arsdk_Camera_Command.ResetZoom?
        var hadOneofValue = false
        if let current = self.id {
          hadOneofValue = true
          if case .resetZoom(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.id = .resetZoom(v)
        }
      }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    switch self.id {
    case .setZoomTarget?: try {
      guard case .setZoomTarget(let v)? = self.id else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .listCameras?: try {
      guard case .listCameras(let v)? = self.id else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 16)
    }()
    case .getState?: try {
      guard case .getState(let v)? = self.id else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 17)
    }()
    case .configure?: try {
      guard case .configure(let v)? = self.id else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 18)
    }()
    case .startPhoto?: try {
      guard case .startPhoto(let v)? = self.id else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 19)
    }()
    case .stopPhoto?: try {
      guard case .stopPhoto(let v)? = self.id else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 20)
    }()
    case .startRecording?: try {
      guard case .startRecording(let v)? = self.id else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 21)
    }()
    case .stopRecording?: try {
      guard case .stopRecording(let v)? = self.id else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 22)
    }()
    case .lockExposure?: try {
      guard case .lockExposure(let v)? = self.id else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 23)
    }()
    case .lockWhiteBalance?: try {
      guard case .lockWhiteBalance(let v)? = self.id else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 24)
    }()
    case .setMediaMetadata?: try {
      guard case .setMediaMetadata(let v)? = self.id else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 25)
    }()
    case .resetZoom?: try {
      guard case .resetZoom(let v)? = self.id else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 26)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Arsdk_Camera_Command, rhs: Arsdk_Camera_Command) -> Bool {
    if lhs.id != rhs.id {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Arsdk_Camera_Command.ListCameras: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Arsdk_Camera_Command.protoMessageName + ".ListCameras"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "model_filter"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedEnumField(value: &self.modelFilter) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.modelFilter.isEmpty {
      try visitor.visitPackedEnumField(value: self.modelFilter, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Arsdk_Camera_Command.ListCameras, rhs: Arsdk_Camera_Command.ListCameras) -> Bool {
    if lhs.modelFilter != rhs.modelFilter {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Arsdk_Camera_Command.GetState: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Arsdk_Camera_Command.protoMessageName + ".GetState"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "camera_id"),
    2: .standard(proto: "include_default_capabilities"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt64Field(value: &self.cameraID) }()
      case 2: try { try decoder.decodeSingularBoolField(value: &self.includeDefaultCapabilities) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.cameraID != 0 {
      try visitor.visitSingularUInt64Field(value: self.cameraID, fieldNumber: 1)
    }
    if self.includeDefaultCapabilities != false {
      try visitor.visitSingularBoolField(value: self.includeDefaultCapabilities, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Arsdk_Camera_Command.GetState, rhs: Arsdk_Camera_Command.GetState) -> Bool {
    if lhs.cameraID != rhs.cameraID {return false}
    if lhs.includeDefaultCapabilities != rhs.includeDefaultCapabilities {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Arsdk_Camera_Command.Configure: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Arsdk_Camera_Command.protoMessageName + ".Configure"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "camera_id"),
    2: .same(proto: "config"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt64Field(value: &self.cameraID) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._config) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if self.cameraID != 0 {
      try visitor.visitSingularUInt64Field(value: self.cameraID, fieldNumber: 1)
    }
    try { if let v = self._config {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Arsdk_Camera_Command.Configure, rhs: Arsdk_Camera_Command.Configure) -> Bool {
    if lhs.cameraID != rhs.cameraID {return false}
    if lhs._config != rhs._config {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Arsdk_Camera_Command.SetZoomTarget: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Arsdk_Camera_Command.protoMessageName + ".SetZoomTarget"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "camera_id"),
    2: .standard(proto: "control_mode"),
    3: .same(proto: "target"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt64Field(value: &self.cameraID) }()
      case 2: try { try decoder.decodeSingularEnumField(value: &self.controlMode) }()
      case 3: try { try decoder.decodeSingularDoubleField(value: &self.target) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.cameraID != 0 {
      try visitor.visitSingularUInt64Field(value: self.cameraID, fieldNumber: 1)
    }
    if self.controlMode != .level {
      try visitor.visitSingularEnumField(value: self.controlMode, fieldNumber: 2)
    }
    if self.target != 0 {
      try visitor.visitSingularDoubleField(value: self.target, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Arsdk_Camera_Command.SetZoomTarget, rhs: Arsdk_Camera_Command.SetZoomTarget) -> Bool {
    if lhs.cameraID != rhs.cameraID {return false}
    if lhs.controlMode != rhs.controlMode {return false}
    if lhs.target != rhs.target {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Arsdk_Camera_Command.ResetZoom: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Arsdk_Camera_Command.protoMessageName + ".ResetZoom"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "camera_id"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt64Field(value: &self.cameraID) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.cameraID != 0 {
      try visitor.visitSingularUInt64Field(value: self.cameraID, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Arsdk_Camera_Command.ResetZoom, rhs: Arsdk_Camera_Command.ResetZoom) -> Bool {
    if lhs.cameraID != rhs.cameraID {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Arsdk_Camera_Command.StartPhoto: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Arsdk_Camera_Command.protoMessageName + ".StartPhoto"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "camera_id"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt64Field(value: &self.cameraID) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.cameraID != 0 {
      try visitor.visitSingularUInt64Field(value: self.cameraID, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Arsdk_Camera_Command.StartPhoto, rhs: Arsdk_Camera_Command.StartPhoto) -> Bool {
    if lhs.cameraID != rhs.cameraID {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Arsdk_Camera_Command.StopPhoto: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Arsdk_Camera_Command.protoMessageName + ".StopPhoto"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "camera_id"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt64Field(value: &self.cameraID) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.cameraID != 0 {
      try visitor.visitSingularUInt64Field(value: self.cameraID, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Arsdk_Camera_Command.StopPhoto, rhs: Arsdk_Camera_Command.StopPhoto) -> Bool {
    if lhs.cameraID != rhs.cameraID {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Arsdk_Camera_Command.StartRecording: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Arsdk_Camera_Command.protoMessageName + ".StartRecording"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "camera_id"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt64Field(value: &self.cameraID) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.cameraID != 0 {
      try visitor.visitSingularUInt64Field(value: self.cameraID, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Arsdk_Camera_Command.StartRecording, rhs: Arsdk_Camera_Command.StartRecording) -> Bool {
    if lhs.cameraID != rhs.cameraID {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Arsdk_Camera_Command.StopRecording: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Arsdk_Camera_Command.protoMessageName + ".StopRecording"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "camera_id"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt64Field(value: &self.cameraID) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.cameraID != 0 {
      try visitor.visitSingularUInt64Field(value: self.cameraID, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Arsdk_Camera_Command.StopRecording, rhs: Arsdk_Camera_Command.StopRecording) -> Bool {
    if lhs.cameraID != rhs.cameraID {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Arsdk_Camera_Command.LockExposure: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Arsdk_Camera_Command.protoMessageName + ".LockExposure"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "camera_id"),
    2: .same(proto: "mode"),
    3: .same(proto: "roi"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt64Field(value: &self.cameraID) }()
      case 2: try { try decoder.decodeSingularEnumField(value: &self.mode) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._roi) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if self.cameraID != 0 {
      try visitor.visitSingularUInt64Field(value: self.cameraID, fieldNumber: 1)
    }
    if self.mode != .unlocked {
      try visitor.visitSingularEnumField(value: self.mode, fieldNumber: 2)
    }
    try { if let v = self._roi {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Arsdk_Camera_Command.LockExposure, rhs: Arsdk_Camera_Command.LockExposure) -> Bool {
    if lhs.cameraID != rhs.cameraID {return false}
    if lhs.mode != rhs.mode {return false}
    if lhs._roi != rhs._roi {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Arsdk_Camera_Command.LockWhiteBalance: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Arsdk_Camera_Command.protoMessageName + ".LockWhiteBalance"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "camera_id"),
    2: .same(proto: "mode"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt64Field(value: &self.cameraID) }()
      case 2: try { try decoder.decodeSingularEnumField(value: &self.mode) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.cameraID != 0 {
      try visitor.visitSingularUInt64Field(value: self.cameraID, fieldNumber: 1)
    }
    if self.mode != .unlocked {
      try visitor.visitSingularEnumField(value: self.mode, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Arsdk_Camera_Command.LockWhiteBalance, rhs: Arsdk_Camera_Command.LockWhiteBalance) -> Bool {
    if lhs.cameraID != rhs.cameraID {return false}
    if lhs.mode != rhs.mode {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Arsdk_Camera_Command.SetMediaMetadata: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Arsdk_Camera_Command.protoMessageName + ".SetMediaMetadata"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "camera_id"),
    2: .same(proto: "metadata"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt64Field(value: &self.cameraID) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._metadata) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if self.cameraID != 0 {
      try visitor.visitSingularUInt64Field(value: self.cameraID, fieldNumber: 1)
    }
    try { if let v = self._metadata {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Arsdk_Camera_Command.SetMediaMetadata, rhs: Arsdk_Camera_Command.SetMediaMetadata) -> Bool {
    if lhs.cameraID != rhs.cameraID {return false}
    if lhs._metadata != rhs._metadata {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Arsdk_Camera_Event: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".Event"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "camera_exposure"),
    2: .standard(proto: "zoom_level"),
    3: .standard(proto: "next_photo_interval"),
    16: .standard(proto: "camera_list"),
    17: .same(proto: "state"),
    18: .same(proto: "photo"),
    19: .same(proto: "recording"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Arsdk_Camera_Event.Exposure?
        var hadOneofValue = false
        if let current = self.id {
          hadOneofValue = true
          if case .cameraExposure(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.id = .cameraExposure(v)
        }
      }()
      case 2: try {
        var v: Arsdk_Camera_Event.ZoomLevel?
        var hadOneofValue = false
        if let current = self.id {
          hadOneofValue = true
          if case .zoomLevel(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.id = .zoomLevel(v)
        }
      }()
      case 3: try {
        var v: Arsdk_Camera_Event.NextPhotoInterval?
        var hadOneofValue = false
        if let current = self.id {
          hadOneofValue = true
          if case .nextPhotoInterval(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.id = .nextPhotoInterval(v)
        }
      }()
      case 16: try {
        var v: Arsdk_Camera_Event.CameraList?
        var hadOneofValue = false
        if let current = self.id {
          hadOneofValue = true
          if case .cameraList(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.id = .cameraList(v)
        }
      }()
      case 17: try {
        var v: Arsdk_Camera_Event.State?
        var hadOneofValue = false
        if let current = self.id {
          hadOneofValue = true
          if case .state(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.id = .state(v)
        }
      }()
      case 18: try {
        var v: Arsdk_Camera_Event.Photo?
        var hadOneofValue = false
        if let current = self.id {
          hadOneofValue = true
          if case .photo(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.id = .photo(v)
        }
      }()
      case 19: try {
        var v: Arsdk_Camera_Event.Recording?
        var hadOneofValue = false
        if let current = self.id {
          hadOneofValue = true
          if case .recording(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.id = .recording(v)
        }
      }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    switch self.id {
    case .cameraExposure?: try {
      guard case .cameraExposure(let v)? = self.id else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .zoomLevel?: try {
      guard case .zoomLevel(let v)? = self.id else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }()
    case .nextPhotoInterval?: try {
      guard case .nextPhotoInterval(let v)? = self.id else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    }()
    case .cameraList?: try {
      guard case .cameraList(let v)? = self.id else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 16)
    }()
    case .state?: try {
      guard case .state(let v)? = self.id else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 17)
    }()
    case .photo?: try {
      guard case .photo(let v)? = self.id else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 18)
    }()
    case .recording?: try {
      guard case .recording(let v)? = self.id else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 19)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Arsdk_Camera_Event, rhs: Arsdk_Camera_Event) -> Bool {
    if lhs.id != rhs.id {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Arsdk_Camera_Event.CameraList: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Arsdk_Camera_Event.protoMessageName + ".CameraList"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "cameras"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufEnumMap<SwiftProtobuf.ProtobufUInt64,Arsdk_Camera_CameraModel>.self, value: &self.cameras) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.cameras.isEmpty {
      try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufEnumMap<SwiftProtobuf.ProtobufUInt64,Arsdk_Camera_CameraModel>.self, value: self.cameras, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Arsdk_Camera_Event.CameraList, rhs: Arsdk_Camera_Event.CameraList) -> Bool {
    if lhs.cameras != rhs.cameras {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Arsdk_Camera_Event.State: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Arsdk_Camera_Event.protoMessageName + ".State"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "camera_id"),
    2: .standard(proto: "selected_fields"),
    3: .same(proto: "active"),
    4: .standard(proto: "default_capabilities"),
    5: .standard(proto: "current_capabilities"),
    6: .same(proto: "config"),
    7: .same(proto: "photo"),
    8: .same(proto: "recording"),
    9: .standard(proto: "white_balance_lock"),
    10: .standard(proto: "exposure_lock"),
    11: .same(proto: "zoom"),
    12: .standard(proto: "media_metadata"),
  ]

  fileprivate class _StorageClass {
    var _cameraID: UInt64 = 0
    var _selectedFields: Dictionary<UInt32,SwiftProtobuf.Google_Protobuf_Empty> = [:]
    var _active: Bool = false
    var _defaultCapabilities: Arsdk_Camera_Capabilities? = nil
    var _currentCapabilities: Arsdk_Camera_Capabilities? = nil
    var _config: Arsdk_Camera_Config? = nil
    var _photo: Arsdk_Camera_Event.State.Photo? = nil
    var _recording: Arsdk_Camera_Event.State.Recording? = nil
    var _whiteBalanceLock: Arsdk_Camera_Event.State.WhiteBalanceLock? = nil
    var _exposureLock: Arsdk_Camera_Event.State.ExposureLock? = nil
    var _zoom: Arsdk_Camera_Event.State.Zoom? = nil
    var _mediaMetadata: Arsdk_Camera_MediaMetadata? = nil

    static let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _cameraID = source._cameraID
      _selectedFields = source._selectedFields
      _active = source._active
      _defaultCapabilities = source._defaultCapabilities
      _currentCapabilities = source._currentCapabilities
      _config = source._config
      _photo = source._photo
      _recording = source._recording
      _whiteBalanceLock = source._whiteBalanceLock
      _exposureLock = source._exposureLock
      _zoom = source._zoom
      _mediaMetadata = source._mediaMetadata
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularUInt64Field(value: &_storage._cameraID) }()
        case 2: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMessageMap<SwiftProtobuf.ProtobufUInt32,SwiftProtobuf.Google_Protobuf_Empty>.self, value: &_storage._selectedFields) }()
        case 3: try { try decoder.decodeSingularBoolField(value: &_storage._active) }()
        case 4: try { try decoder.decodeSingularMessageField(value: &_storage._defaultCapabilities) }()
        case 5: try { try decoder.decodeSingularMessageField(value: &_storage._currentCapabilities) }()
        case 6: try { try decoder.decodeSingularMessageField(value: &_storage._config) }()
        case 7: try { try decoder.decodeSingularMessageField(value: &_storage._photo) }()
        case 8: try { try decoder.decodeSingularMessageField(value: &_storage._recording) }()
        case 9: try { try decoder.decodeSingularMessageField(value: &_storage._whiteBalanceLock) }()
        case 10: try { try decoder.decodeSingularMessageField(value: &_storage._exposureLock) }()
        case 11: try { try decoder.decodeSingularMessageField(value: &_storage._zoom) }()
        case 12: try { try decoder.decodeSingularMessageField(value: &_storage._mediaMetadata) }()
        default: break
        }
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      if _storage._cameraID != 0 {
        try visitor.visitSingularUInt64Field(value: _storage._cameraID, fieldNumber: 1)
      }
      if !_storage._selectedFields.isEmpty {
        try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMessageMap<SwiftProtobuf.ProtobufUInt32,SwiftProtobuf.Google_Protobuf_Empty>.self, value: _storage._selectedFields, fieldNumber: 2)
      }
      if _storage._active != false {
        try visitor.visitSingularBoolField(value: _storage._active, fieldNumber: 3)
      }
      try { if let v = _storage._defaultCapabilities {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
      } }()
      try { if let v = _storage._currentCapabilities {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
      } }()
      try { if let v = _storage._config {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
      } }()
      try { if let v = _storage._photo {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
      } }()
      try { if let v = _storage._recording {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
      } }()
      try { if let v = _storage._whiteBalanceLock {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 9)
      } }()
      try { if let v = _storage._exposureLock {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 10)
      } }()
      try { if let v = _storage._zoom {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 11)
      } }()
      try { if let v = _storage._mediaMetadata {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 12)
      } }()
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Arsdk_Camera_Event.State, rhs: Arsdk_Camera_Event.State) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._cameraID != rhs_storage._cameraID {return false}
        if _storage._selectedFields != rhs_storage._selectedFields {return false}
        if _storage._active != rhs_storage._active {return false}
        if _storage._defaultCapabilities != rhs_storage._defaultCapabilities {return false}
        if _storage._currentCapabilities != rhs_storage._currentCapabilities {return false}
        if _storage._config != rhs_storage._config {return false}
        if _storage._photo != rhs_storage._photo {return false}
        if _storage._recording != rhs_storage._recording {return false}
        if _storage._whiteBalanceLock != rhs_storage._whiteBalanceLock {return false}
        if _storage._exposureLock != rhs_storage._exposureLock {return false}
        if _storage._zoom != rhs_storage._zoom {return false}
        if _storage._mediaMetadata != rhs_storage._mediaMetadata {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Arsdk_Camera_Event.State.Photo: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Arsdk_Camera_Event.State.protoMessageName + ".Photo"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "state"),
    2: .standard(proto: "start_timestamp"),
    3: .standard(proto: "photo_count"),
    4: .same(proto: "storage"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularEnumField(value: &self.state) }()
      case 2: try { try decoder.decodeSingularUInt64Field(value: &self.startTimestamp) }()
      case 3: try { try decoder.decodeSingularUInt32Field(value: &self.photoCount) }()
      case 4: try { try decoder.decodeSingularEnumField(value: &self.storage) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.state != .unavailable {
      try visitor.visitSingularEnumField(value: self.state, fieldNumber: 1)
    }
    if self.startTimestamp != 0 {
      try visitor.visitSingularUInt64Field(value: self.startTimestamp, fieldNumber: 2)
    }
    if self.photoCount != 0 {
      try visitor.visitSingularUInt32Field(value: self.photoCount, fieldNumber: 3)
    }
    if self.storage != .internal {
      try visitor.visitSingularEnumField(value: self.storage, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Arsdk_Camera_Event.State.Photo, rhs: Arsdk_Camera_Event.State.Photo) -> Bool {
    if lhs.state != rhs.state {return false}
    if lhs.startTimestamp != rhs.startTimestamp {return false}
    if lhs.photoCount != rhs.photoCount {return false}
    if lhs.storage != rhs.storage {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Arsdk_Camera_Event.State.Recording: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Arsdk_Camera_Event.State.protoMessageName + ".Recording"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "state"),
    2: .standard(proto: "start_timestamp"),
    3: .standard(proto: "video_bitrate"),
    4: .same(proto: "storage"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularEnumField(value: &self.state) }()
      case 2: try { try decoder.decodeSingularUInt64Field(value: &self.startTimestamp) }()
      case 3: try { try decoder.decodeSingularUInt32Field(value: &self.videoBitrate) }()
      case 4: try { try decoder.decodeSingularEnumField(value: &self.storage) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.state != .unavailable {
      try visitor.visitSingularEnumField(value: self.state, fieldNumber: 1)
    }
    if self.startTimestamp != 0 {
      try visitor.visitSingularUInt64Field(value: self.startTimestamp, fieldNumber: 2)
    }
    if self.videoBitrate != 0 {
      try visitor.visitSingularUInt32Field(value: self.videoBitrate, fieldNumber: 3)
    }
    if self.storage != .internal {
      try visitor.visitSingularEnumField(value: self.storage, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Arsdk_Camera_Event.State.Recording, rhs: Arsdk_Camera_Event.State.Recording) -> Bool {
    if lhs.state != rhs.state {return false}
    if lhs.startTimestamp != rhs.startTimestamp {return false}
    if lhs.videoBitrate != rhs.videoBitrate {return false}
    if lhs.storage != rhs.storage {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Arsdk_Camera_Event.State.WhiteBalanceLock: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Arsdk_Camera_Event.State.protoMessageName + ".WhiteBalanceLock"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "supported_modes"),
    2: .same(proto: "mode"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedEnumField(value: &self.supportedModes) }()
      case 2: try { try decoder.decodeSingularEnumField(value: &self.mode) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.supportedModes.isEmpty {
      try visitor.visitPackedEnumField(value: self.supportedModes, fieldNumber: 1)
    }
    if self.mode != .unlocked {
      try visitor.visitSingularEnumField(value: self.mode, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Arsdk_Camera_Event.State.WhiteBalanceLock, rhs: Arsdk_Camera_Event.State.WhiteBalanceLock) -> Bool {
    if lhs.supportedModes != rhs.supportedModes {return false}
    if lhs.mode != rhs.mode {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Arsdk_Camera_Event.State.ExposureLock: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Arsdk_Camera_Event.State.protoMessageName + ".ExposureLock"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "supported_modes"),
    2: .same(proto: "mode"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedEnumField(value: &self.supportedModes) }()
      case 2: try { try decoder.decodeSingularEnumField(value: &self.mode) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.supportedModes.isEmpty {
      try visitor.visitPackedEnumField(value: self.supportedModes, fieldNumber: 1)
    }
    if self.mode != .unlocked {
      try visitor.visitSingularEnumField(value: self.mode, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Arsdk_Camera_Event.State.ExposureLock, rhs: Arsdk_Camera_Event.State.ExposureLock) -> Bool {
    if lhs.supportedModes != rhs.supportedModes {return false}
    if lhs.mode != rhs.mode {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Arsdk_Camera_Event.State.Zoom: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Arsdk_Camera_Event.State.protoMessageName + ".Zoom"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "zoom_level_max"),
    2: .standard(proto: "zoom_high_quality_level_max"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularDoubleField(value: &self.zoomLevelMax) }()
      case 2: try { try decoder.decodeSingularDoubleField(value: &self.zoomHighQualityLevelMax) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.zoomLevelMax != 0 {
      try visitor.visitSingularDoubleField(value: self.zoomLevelMax, fieldNumber: 1)
    }
    if self.zoomHighQualityLevelMax != 0 {
      try visitor.visitSingularDoubleField(value: self.zoomHighQualityLevelMax, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Arsdk_Camera_Event.State.Zoom, rhs: Arsdk_Camera_Event.State.Zoom) -> Bool {
    if lhs.zoomLevelMax != rhs.zoomLevelMax {return false}
    if lhs.zoomHighQualityLevelMax != rhs.zoomHighQualityLevelMax {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Arsdk_Camera_Event.Exposure: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Arsdk_Camera_Event.protoMessageName + ".Exposure"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "camera_id"),
    2: .standard(proto: "shutter_speed"),
    3: .standard(proto: "iso_sensitivity"),
    4: .standard(proto: "exposure_lock_region"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt64Field(value: &self.cameraID) }()
      case 2: try { try decoder.decodeSingularEnumField(value: &self.shutterSpeed) }()
      case 3: try { try decoder.decodeSingularEnumField(value: &self.isoSensitivity) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._exposureLockRegion) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if self.cameraID != 0 {
      try visitor.visitSingularUInt64Field(value: self.cameraID, fieldNumber: 1)
    }
    if self.shutterSpeed != .shutterSpeed1Over10000 {
      try visitor.visitSingularEnumField(value: self.shutterSpeed, fieldNumber: 2)
    }
    if self.isoSensitivity != .isoSensitivity25 {
      try visitor.visitSingularEnumField(value: self.isoSensitivity, fieldNumber: 3)
    }
    try { if let v = self._exposureLockRegion {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Arsdk_Camera_Event.Exposure, rhs: Arsdk_Camera_Event.Exposure) -> Bool {
    if lhs.cameraID != rhs.cameraID {return false}
    if lhs.shutterSpeed != rhs.shutterSpeed {return false}
    if lhs.isoSensitivity != rhs.isoSensitivity {return false}
    if lhs._exposureLockRegion != rhs._exposureLockRegion {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Arsdk_Camera_Event.ZoomLevel: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Arsdk_Camera_Event.protoMessageName + ".ZoomLevel"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "camera_id"),
    2: .same(proto: "level"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt64Field(value: &self.cameraID) }()
      case 2: try { try decoder.decodeSingularDoubleField(value: &self.level) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.cameraID != 0 {
      try visitor.visitSingularUInt64Field(value: self.cameraID, fieldNumber: 1)
    }
    if self.level != 0 {
      try visitor.visitSingularDoubleField(value: self.level, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Arsdk_Camera_Event.ZoomLevel, rhs: Arsdk_Camera_Event.ZoomLevel) -> Bool {
    if lhs.cameraID != rhs.cameraID {return false}
    if lhs.level != rhs.level {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Arsdk_Camera_Event.NextPhotoInterval: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Arsdk_Camera_Event.protoMessageName + ".NextPhotoInterval"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "camera_id"),
    2: .same(proto: "mode"),
    3: .same(proto: "interval"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt64Field(value: &self.cameraID) }()
      case 2: try { try decoder.decodeSingularEnumField(value: &self.mode) }()
      case 3: try { try decoder.decodeSingularDoubleField(value: &self.interval) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.cameraID != 0 {
      try visitor.visitSingularUInt64Field(value: self.cameraID, fieldNumber: 1)
    }
    if self.mode != .single {
      try visitor.visitSingularEnumField(value: self.mode, fieldNumber: 2)
    }
    if self.interval != 0 {
      try visitor.visitSingularDoubleField(value: self.interval, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Arsdk_Camera_Event.NextPhotoInterval, rhs: Arsdk_Camera_Event.NextPhotoInterval) -> Bool {
    if lhs.cameraID != rhs.cameraID {return false}
    if lhs.mode != rhs.mode {return false}
    if lhs.interval != rhs.interval {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Arsdk_Camera_Event.Photo: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Arsdk_Camera_Event.protoMessageName + ".Photo"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "camera_id"),
    2: .same(proto: "type"),
    3: .standard(proto: "media_id"),
    4: .standard(proto: "stop_reason"),
    5: .standard(proto: "resource_id"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt64Field(value: &self.cameraID) }()
      case 2: try { try decoder.decodeSingularEnumField(value: &self.type) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.mediaID) }()
      case 4: try { try decoder.decodeSingularEnumField(value: &self.stopReason) }()
      case 5: try { try decoder.decodeSingularStringField(value: &self.resourceID) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.cameraID != 0 {
      try visitor.visitSingularUInt64Field(value: self.cameraID, fieldNumber: 1)
    }
    if self.type != .start {
      try visitor.visitSingularEnumField(value: self.type, fieldNumber: 2)
    }
    if !self.mediaID.isEmpty {
      try visitor.visitSingularStringField(value: self.mediaID, fieldNumber: 3)
    }
    if self.stopReason != .userRequest {
      try visitor.visitSingularEnumField(value: self.stopReason, fieldNumber: 4)
    }
    if !self.resourceID.isEmpty {
      try visitor.visitSingularStringField(value: self.resourceID, fieldNumber: 5)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Arsdk_Camera_Event.Photo, rhs: Arsdk_Camera_Event.Photo) -> Bool {
    if lhs.cameraID != rhs.cameraID {return false}
    if lhs.type != rhs.type {return false}
    if lhs.mediaID != rhs.mediaID {return false}
    if lhs.stopReason != rhs.stopReason {return false}
    if lhs.resourceID != rhs.resourceID {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Arsdk_Camera_Event.Recording: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Arsdk_Camera_Event.protoMessageName + ".Recording"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "camera_id"),
    2: .same(proto: "type"),
    3: .standard(proto: "media_id"),
    4: .standard(proto: "stop_reason"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt64Field(value: &self.cameraID) }()
      case 2: try { try decoder.decodeSingularEnumField(value: &self.type) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.mediaID) }()
      case 4: try { try decoder.decodeSingularEnumField(value: &self.stopReason) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.cameraID != 0 {
      try visitor.visitSingularUInt64Field(value: self.cameraID, fieldNumber: 1)
    }
    if self.type != .start {
      try visitor.visitSingularEnumField(value: self.type, fieldNumber: 2)
    }
    if !self.mediaID.isEmpty {
      try visitor.visitSingularStringField(value: self.mediaID, fieldNumber: 3)
    }
    if self.stopReason != .userRequest {
      try visitor.visitSingularEnumField(value: self.stopReason, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Arsdk_Camera_Event.Recording, rhs: Arsdk_Camera_Event.Recording) -> Bool {
    if lhs.cameraID != rhs.cameraID {return false}
    if lhs.type != rhs.type {return false}
    if lhs.mediaID != rhs.mediaID {return false}
    if lhs.stopReason != rhs.stopReason {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Arsdk_Camera_Capabilities: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".Capabilities"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "rules"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.rules) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.rules.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.rules, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Arsdk_Camera_Capabilities, rhs: Arsdk_Camera_Capabilities) -> Bool {
    if lhs.rules != rhs.rules {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Arsdk_Camera_Capabilities.Rule: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Arsdk_Camera_Capabilities.protoMessageName + ".Rule"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "index"),
    2: .standard(proto: "selected_fields"),
    3: .standard(proto: "camera_modes"),
    4: .standard(proto: "photo_modes"),
    5: .standard(proto: "photo_dynamic_ranges"),
    6: .standard(proto: "photo_resolutions"),
    7: .standard(proto: "photo_formats"),
    8: .standard(proto: "photo_file_formats"),
    9: .standard(proto: "photo_burst_values"),
    10: .standard(proto: "photo_bracketing_presets"),
    11: .standard(proto: "photo_time_lapse_interval_range"),
    12: .standard(proto: "photo_gps_lapse_interval_range"),
    13: .standard(proto: "photo_streaming_modes"),
    14: .standard(proto: "video_recording_modes"),
    15: .standard(proto: "video_recording_dynamic_ranges"),
    16: .standard(proto: "video_recording_codecs"),
    17: .standard(proto: "video_recording_resolutions"),
    18: .standard(proto: "video_recording_framerates"),
    20: .standard(proto: "audio_recording_modes"),
    23: .standard(proto: "exposure_modes"),
    24: .standard(proto: "exposure_manual_shutter_speeds"),
    25: .standard(proto: "exposure_manual_iso_sensitivities"),
    26: .standard(proto: "exposure_maximum_iso_sensitivities"),
    27: .standard(proto: "white_balance_modes"),
    28: .standard(proto: "white_balance_temperatures"),
    29: .standard(proto: "ev_compensations"),
    30: .standard(proto: "image_styles"),
    31: .standard(proto: "image_contrast_range"),
    32: .standard(proto: "image_saturation_range"),
    33: .standard(proto: "image_sharpness_range"),
    34: .standard(proto: "zoom_max_speed_range"),
    35: .standard(proto: "zoom_velocity_control_quality_modes"),
    36: .standard(proto: "auto_record_modes"),
    37: .standard(proto: "alignment_offset_pitch_range"),
    38: .standard(proto: "alignment_offset_roll_range"),
    39: .standard(proto: "alignment_offset_yaw_range"),
    40: .standard(proto: "photo_signatures"),
    41: .standard(proto: "exposure_meterings"),
    42: .standard(proto: "storage_policies"),
    43: .standard(proto: "video_recording_bitrates"),
  ]

  fileprivate class _StorageClass {
    var _index: UInt64 = 0
    var _selectedFields: Dictionary<UInt32,SwiftProtobuf.Google_Protobuf_Empty> = [:]
    var _cameraModes: [Arsdk_Camera_CameraMode] = []
    var _photoModes: [Arsdk_Camera_PhotoMode] = []
    var _photoDynamicRanges: [Arsdk_Camera_DynamicRange] = []
    var _photoResolutions: [Arsdk_Camera_PhotoResolution] = []
    var _photoFormats: [Arsdk_Camera_PhotoFormat] = []
    var _photoFileFormats: [Arsdk_Camera_PhotoFileFormat] = []
    var _photoBurstValues: [Arsdk_Camera_BurstValue] = []
    var _photoBracketingPresets: [Arsdk_Camera_BracketingPreset] = []
    var _photoTimeLapseIntervalRange: Arsdk_Camera_DoubleRange? = nil
    var _photoGpsLapseIntervalRange: Arsdk_Camera_DoubleRange? = nil
    var _photoStreamingModes: [Arsdk_Camera_PhotoStreamingMode] = []
    var _videoRecordingModes: [Arsdk_Camera_VideoRecordingMode] = []
    var _videoRecordingDynamicRanges: [Arsdk_Camera_DynamicRange] = []
    var _videoRecordingCodecs: [Arsdk_Camera_VideoCodec] = []
    var _videoRecordingResolutions: [Arsdk_Camera_VideoResolution] = []
    var _videoRecordingFramerates: [Arsdk_Camera_Framerate] = []
    var _audioRecordingModes: [Arsdk_Camera_AudioRecordingMode] = []
    var _exposureModes: [Arsdk_Camera_ExposureMode] = []
    var _exposureManualShutterSpeeds: [Arsdk_Camera_ShutterSpeed] = []
    var _exposureManualIsoSensitivities: [Arsdk_Camera_IsoSensitivity] = []
    var _exposureMaximumIsoSensitivities: [Arsdk_Camera_IsoSensitivity] = []
    var _whiteBalanceModes: [Arsdk_Camera_WhiteBalanceMode] = []
    var _whiteBalanceTemperatures: [Arsdk_Camera_WhiteBalanceTemperature] = []
    var _evCompensations: [Arsdk_Camera_EvCompensation] = []
    var _imageStyles: [Arsdk_Camera_ImageStyle] = []
    var _imageContrastRange: Arsdk_Camera_DoubleRange? = nil
    var _imageSaturationRange: Arsdk_Camera_DoubleRange? = nil
    var _imageSharpnessRange: Arsdk_Camera_DoubleRange? = nil
    var _zoomMaxSpeedRange: Arsdk_Camera_DoubleRange? = nil
    var _zoomVelocityControlQualityModes: [Arsdk_Camera_ZoomVelocityControlQualityMode] = []
    var _autoRecordModes: [Arsdk_Camera_AutoRecordMode] = []
    var _alignmentOffsetPitchRange: Arsdk_Camera_DoubleRange? = nil
    var _alignmentOffsetRollRange: Arsdk_Camera_DoubleRange? = nil
    var _alignmentOffsetYawRange: Arsdk_Camera_DoubleRange? = nil
    var _photoSignatures: [Arsdk_Camera_DigitalSignature] = []
    var _exposureMeterings: [Arsdk_Camera_ExposureMetering] = []
    var _storagePolicies: [Arsdk_Camera_StoragePolicy] = []
    var _videoRecordingBitrates: [UInt32] = []

    static let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _index = source._index
      _selectedFields = source._selectedFields
      _cameraModes = source._cameraModes
      _photoModes = source._photoModes
      _photoDynamicRanges = source._photoDynamicRanges
      _photoResolutions = source._photoResolutions
      _photoFormats = source._photoFormats
      _photoFileFormats = source._photoFileFormats
      _photoBurstValues = source._photoBurstValues
      _photoBracketingPresets = source._photoBracketingPresets
      _photoTimeLapseIntervalRange = source._photoTimeLapseIntervalRange
      _photoGpsLapseIntervalRange = source._photoGpsLapseIntervalRange
      _photoStreamingModes = source._photoStreamingModes
      _videoRecordingModes = source._videoRecordingModes
      _videoRecordingDynamicRanges = source._videoRecordingDynamicRanges
      _videoRecordingCodecs = source._videoRecordingCodecs
      _videoRecordingResolutions = source._videoRecordingResolutions
      _videoRecordingFramerates = source._videoRecordingFramerates
      _audioRecordingModes = source._audioRecordingModes
      _exposureModes = source._exposureModes
      _exposureManualShutterSpeeds = source._exposureManualShutterSpeeds
      _exposureManualIsoSensitivities = source._exposureManualIsoSensitivities
      _exposureMaximumIsoSensitivities = source._exposureMaximumIsoSensitivities
      _whiteBalanceModes = source._whiteBalanceModes
      _whiteBalanceTemperatures = source._whiteBalanceTemperatures
      _evCompensations = source._evCompensations
      _imageStyles = source._imageStyles
      _imageContrastRange = source._imageContrastRange
      _imageSaturationRange = source._imageSaturationRange
      _imageSharpnessRange = source._imageSharpnessRange
      _zoomMaxSpeedRange = source._zoomMaxSpeedRange
      _zoomVelocityControlQualityModes = source._zoomVelocityControlQualityModes
      _autoRecordModes = source._autoRecordModes
      _alignmentOffsetPitchRange = source._alignmentOffsetPitchRange
      _alignmentOffsetRollRange = source._alignmentOffsetRollRange
      _alignmentOffsetYawRange = source._alignmentOffsetYawRange
      _photoSignatures = source._photoSignatures
      _exposureMeterings = source._exposureMeterings
      _storagePolicies = source._storagePolicies
      _videoRecordingBitrates = source._videoRecordingBitrates
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularUInt64Field(value: &_storage._index) }()
        case 2: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMessageMap<SwiftProtobuf.ProtobufUInt32,SwiftProtobuf.Google_Protobuf_Empty>.self, value: &_storage._selectedFields) }()
        case 3: try { try decoder.decodeRepeatedEnumField(value: &_storage._cameraModes) }()
        case 4: try { try decoder.decodeRepeatedEnumField(value: &_storage._photoModes) }()
        case 5: try { try decoder.decodeRepeatedEnumField(value: &_storage._photoDynamicRanges) }()
        case 6: try { try decoder.decodeRepeatedEnumField(value: &_storage._photoResolutions) }()
        case 7: try { try decoder.decodeRepeatedEnumField(value: &_storage._photoFormats) }()
        case 8: try { try decoder.decodeRepeatedEnumField(value: &_storage._photoFileFormats) }()
        case 9: try { try decoder.decodeRepeatedEnumField(value: &_storage._photoBurstValues) }()
        case 10: try { try decoder.decodeRepeatedEnumField(value: &_storage._photoBracketingPresets) }()
        case 11: try { try decoder.decodeSingularMessageField(value: &_storage._photoTimeLapseIntervalRange) }()
        case 12: try { try decoder.decodeSingularMessageField(value: &_storage._photoGpsLapseIntervalRange) }()
        case 13: try { try decoder.decodeRepeatedEnumField(value: &_storage._photoStreamingModes) }()
        case 14: try { try decoder.decodeRepeatedEnumField(value: &_storage._videoRecordingModes) }()
        case 15: try { try decoder.decodeRepeatedEnumField(value: &_storage._videoRecordingDynamicRanges) }()
        case 16: try { try decoder.decodeRepeatedEnumField(value: &_storage._videoRecordingCodecs) }()
        case 17: try { try decoder.decodeRepeatedEnumField(value: &_storage._videoRecordingResolutions) }()
        case 18: try { try decoder.decodeRepeatedEnumField(value: &_storage._videoRecordingFramerates) }()
        case 20: try { try decoder.decodeRepeatedEnumField(value: &_storage._audioRecordingModes) }()
        case 23: try { try decoder.decodeRepeatedEnumField(value: &_storage._exposureModes) }()
        case 24: try { try decoder.decodeRepeatedEnumField(value: &_storage._exposureManualShutterSpeeds) }()
        case 25: try { try decoder.decodeRepeatedEnumField(value: &_storage._exposureManualIsoSensitivities) }()
        case 26: try { try decoder.decodeRepeatedEnumField(value: &_storage._exposureMaximumIsoSensitivities) }()
        case 27: try { try decoder.decodeRepeatedEnumField(value: &_storage._whiteBalanceModes) }()
        case 28: try { try decoder.decodeRepeatedEnumField(value: &_storage._whiteBalanceTemperatures) }()
        case 29: try { try decoder.decodeRepeatedEnumField(value: &_storage._evCompensations) }()
        case 30: try { try decoder.decodeRepeatedEnumField(value: &_storage._imageStyles) }()
        case 31: try { try decoder.decodeSingularMessageField(value: &_storage._imageContrastRange) }()
        case 32: try { try decoder.decodeSingularMessageField(value: &_storage._imageSaturationRange) }()
        case 33: try { try decoder.decodeSingularMessageField(value: &_storage._imageSharpnessRange) }()
        case 34: try { try decoder.decodeSingularMessageField(value: &_storage._zoomMaxSpeedRange) }()
        case 35: try { try decoder.decodeRepeatedEnumField(value: &_storage._zoomVelocityControlQualityModes) }()
        case 36: try { try decoder.decodeRepeatedEnumField(value: &_storage._autoRecordModes) }()
        case 37: try { try decoder.decodeSingularMessageField(value: &_storage._alignmentOffsetPitchRange) }()
        case 38: try { try decoder.decodeSingularMessageField(value: &_storage._alignmentOffsetRollRange) }()
        case 39: try { try decoder.decodeSingularMessageField(value: &_storage._alignmentOffsetYawRange) }()
        case 40: try { try decoder.decodeRepeatedEnumField(value: &_storage._photoSignatures) }()
        case 41: try { try decoder.decodeRepeatedEnumField(value: &_storage._exposureMeterings) }()
        case 42: try { try decoder.decodeRepeatedEnumField(value: &_storage._storagePolicies) }()
        case 43: try { try decoder.decodeRepeatedUInt32Field(value: &_storage._videoRecordingBitrates) }()
        default: break
        }
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      if _storage._index != 0 {
        try visitor.visitSingularUInt64Field(value: _storage._index, fieldNumber: 1)
      }
      if !_storage._selectedFields.isEmpty {
        try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMessageMap<SwiftProtobuf.ProtobufUInt32,SwiftProtobuf.Google_Protobuf_Empty>.self, value: _storage._selectedFields, fieldNumber: 2)
      }
      if !_storage._cameraModes.isEmpty {
        try visitor.visitPackedEnumField(value: _storage._cameraModes, fieldNumber: 3)
      }
      if !_storage._photoModes.isEmpty {
        try visitor.visitPackedEnumField(value: _storage._photoModes, fieldNumber: 4)
      }
      if !_storage._photoDynamicRanges.isEmpty {
        try visitor.visitPackedEnumField(value: _storage._photoDynamicRanges, fieldNumber: 5)
      }
      if !_storage._photoResolutions.isEmpty {
        try visitor.visitPackedEnumField(value: _storage._photoResolutions, fieldNumber: 6)
      }
      if !_storage._photoFormats.isEmpty {
        try visitor.visitPackedEnumField(value: _storage._photoFormats, fieldNumber: 7)
      }
      if !_storage._photoFileFormats.isEmpty {
        try visitor.visitPackedEnumField(value: _storage._photoFileFormats, fieldNumber: 8)
      }
      if !_storage._photoBurstValues.isEmpty {
        try visitor.visitPackedEnumField(value: _storage._photoBurstValues, fieldNumber: 9)
      }
      if !_storage._photoBracketingPresets.isEmpty {
        try visitor.visitPackedEnumField(value: _storage._photoBracketingPresets, fieldNumber: 10)
      }
      try { if let v = _storage._photoTimeLapseIntervalRange {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 11)
      } }()
      try { if let v = _storage._photoGpsLapseIntervalRange {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 12)
      } }()
      if !_storage._photoStreamingModes.isEmpty {
        try visitor.visitPackedEnumField(value: _storage._photoStreamingModes, fieldNumber: 13)
      }
      if !_storage._videoRecordingModes.isEmpty {
        try visitor.visitPackedEnumField(value: _storage._videoRecordingModes, fieldNumber: 14)
      }
      if !_storage._videoRecordingDynamicRanges.isEmpty {
        try visitor.visitPackedEnumField(value: _storage._videoRecordingDynamicRanges, fieldNumber: 15)
      }
      if !_storage._videoRecordingCodecs.isEmpty {
        try visitor.visitPackedEnumField(value: _storage._videoRecordingCodecs, fieldNumber: 16)
      }
      if !_storage._videoRecordingResolutions.isEmpty {
        try visitor.visitPackedEnumField(value: _storage._videoRecordingResolutions, fieldNumber: 17)
      }
      if !_storage._videoRecordingFramerates.isEmpty {
        try visitor.visitPackedEnumField(value: _storage._videoRecordingFramerates, fieldNumber: 18)
      }
      if !_storage._audioRecordingModes.isEmpty {
        try visitor.visitPackedEnumField(value: _storage._audioRecordingModes, fieldNumber: 20)
      }
      if !_storage._exposureModes.isEmpty {
        try visitor.visitPackedEnumField(value: _storage._exposureModes, fieldNumber: 23)
      }
      if !_storage._exposureManualShutterSpeeds.isEmpty {
        try visitor.visitPackedEnumField(value: _storage._exposureManualShutterSpeeds, fieldNumber: 24)
      }
      if !_storage._exposureManualIsoSensitivities.isEmpty {
        try visitor.visitPackedEnumField(value: _storage._exposureManualIsoSensitivities, fieldNumber: 25)
      }
      if !_storage._exposureMaximumIsoSensitivities.isEmpty {
        try visitor.visitPackedEnumField(value: _storage._exposureMaximumIsoSensitivities, fieldNumber: 26)
      }
      if !_storage._whiteBalanceModes.isEmpty {
        try visitor.visitPackedEnumField(value: _storage._whiteBalanceModes, fieldNumber: 27)
      }
      if !_storage._whiteBalanceTemperatures.isEmpty {
        try visitor.visitPackedEnumField(value: _storage._whiteBalanceTemperatures, fieldNumber: 28)
      }
      if !_storage._evCompensations.isEmpty {
        try visitor.visitPackedEnumField(value: _storage._evCompensations, fieldNumber: 29)
      }
      if !_storage._imageStyles.isEmpty {
        try visitor.visitPackedEnumField(value: _storage._imageStyles, fieldNumber: 30)
      }
      try { if let v = _storage._imageContrastRange {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 31)
      } }()
      try { if let v = _storage._imageSaturationRange {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 32)
      } }()
      try { if let v = _storage._imageSharpnessRange {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 33)
      } }()
      try { if let v = _storage._zoomMaxSpeedRange {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 34)
      } }()
      if !_storage._zoomVelocityControlQualityModes.isEmpty {
        try visitor.visitPackedEnumField(value: _storage._zoomVelocityControlQualityModes, fieldNumber: 35)
      }
      if !_storage._autoRecordModes.isEmpty {
        try visitor.visitPackedEnumField(value: _storage._autoRecordModes, fieldNumber: 36)
      }
      try { if let v = _storage._alignmentOffsetPitchRange {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 37)
      } }()
      try { if let v = _storage._alignmentOffsetRollRange {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 38)
      } }()
      try { if let v = _storage._alignmentOffsetYawRange {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 39)
      } }()
      if !_storage._photoSignatures.isEmpty {
        try visitor.visitPackedEnumField(value: _storage._photoSignatures, fieldNumber: 40)
      }
      if !_storage._exposureMeterings.isEmpty {
        try visitor.visitPackedEnumField(value: _storage._exposureMeterings, fieldNumber: 41)
      }
      if !_storage._storagePolicies.isEmpty {
        try visitor.visitPackedEnumField(value: _storage._storagePolicies, fieldNumber: 42)
      }
      if !_storage._videoRecordingBitrates.isEmpty {
        try visitor.visitPackedUInt32Field(value: _storage._videoRecordingBitrates, fieldNumber: 43)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Arsdk_Camera_Capabilities.Rule, rhs: Arsdk_Camera_Capabilities.Rule) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._index != rhs_storage._index {return false}
        if _storage._selectedFields != rhs_storage._selectedFields {return false}
        if _storage._cameraModes != rhs_storage._cameraModes {return false}
        if _storage._photoModes != rhs_storage._photoModes {return false}
        if _storage._photoDynamicRanges != rhs_storage._photoDynamicRanges {return false}
        if _storage._photoResolutions != rhs_storage._photoResolutions {return false}
        if _storage._photoFormats != rhs_storage._photoFormats {return false}
        if _storage._photoFileFormats != rhs_storage._photoFileFormats {return false}
        if _storage._photoBurstValues != rhs_storage._photoBurstValues {return false}
        if _storage._photoBracketingPresets != rhs_storage._photoBracketingPresets {return false}
        if _storage._photoTimeLapseIntervalRange != rhs_storage._photoTimeLapseIntervalRange {return false}
        if _storage._photoGpsLapseIntervalRange != rhs_storage._photoGpsLapseIntervalRange {return false}
        if _storage._photoStreamingModes != rhs_storage._photoStreamingModes {return false}
        if _storage._videoRecordingModes != rhs_storage._videoRecordingModes {return false}
        if _storage._videoRecordingDynamicRanges != rhs_storage._videoRecordingDynamicRanges {return false}
        if _storage._videoRecordingCodecs != rhs_storage._videoRecordingCodecs {return false}
        if _storage._videoRecordingResolutions != rhs_storage._videoRecordingResolutions {return false}
        if _storage._videoRecordingFramerates != rhs_storage._videoRecordingFramerates {return false}
        if _storage._audioRecordingModes != rhs_storage._audioRecordingModes {return false}
        if _storage._exposureModes != rhs_storage._exposureModes {return false}
        if _storage._exposureManualShutterSpeeds != rhs_storage._exposureManualShutterSpeeds {return false}
        if _storage._exposureManualIsoSensitivities != rhs_storage._exposureManualIsoSensitivities {return false}
        if _storage._exposureMaximumIsoSensitivities != rhs_storage._exposureMaximumIsoSensitivities {return false}
        if _storage._whiteBalanceModes != rhs_storage._whiteBalanceModes {return false}
        if _storage._whiteBalanceTemperatures != rhs_storage._whiteBalanceTemperatures {return false}
        if _storage._evCompensations != rhs_storage._evCompensations {return false}
        if _storage._imageStyles != rhs_storage._imageStyles {return false}
        if _storage._imageContrastRange != rhs_storage._imageContrastRange {return false}
        if _storage._imageSaturationRange != rhs_storage._imageSaturationRange {return false}
        if _storage._imageSharpnessRange != rhs_storage._imageSharpnessRange {return false}
        if _storage._zoomMaxSpeedRange != rhs_storage._zoomMaxSpeedRange {return false}
        if _storage._zoomVelocityControlQualityModes != rhs_storage._zoomVelocityControlQualityModes {return false}
        if _storage._autoRecordModes != rhs_storage._autoRecordModes {return false}
        if _storage._alignmentOffsetPitchRange != rhs_storage._alignmentOffsetPitchRange {return false}
        if _storage._alignmentOffsetRollRange != rhs_storage._alignmentOffsetRollRange {return false}
        if _storage._alignmentOffsetYawRange != rhs_storage._alignmentOffsetYawRange {return false}
        if _storage._photoSignatures != rhs_storage._photoSignatures {return false}
        if _storage._exposureMeterings != rhs_storage._exposureMeterings {return false}
        if _storage._storagePolicies != rhs_storage._storagePolicies {return false}
        if _storage._videoRecordingBitrates != rhs_storage._videoRecordingBitrates {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Arsdk_Camera_Config: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".Config"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "selected_fields"),
    2: .standard(proto: "camera_mode"),
    3: .standard(proto: "photo_mode"),
    4: .standard(proto: "photo_dynamic_range"),
    5: .standard(proto: "photo_resolution"),
    6: .standard(proto: "photo_format"),
    7: .standard(proto: "photo_file_format"),
    8: .standard(proto: "photo_burst_value"),
    9: .standard(proto: "photo_bracketing_preset"),
    10: .standard(proto: "photo_time_lapse_interval"),
    11: .standard(proto: "photo_gps_lapse_interval"),
    12: .standard(proto: "photo_streaming_mode"),
    13: .standard(proto: "video_recording_mode"),
    14: .standard(proto: "video_recording_dynamic_range"),
    15: .standard(proto: "video_recording_codec"),
    16: .standard(proto: "video_recording_resolution"),
    17: .standard(proto: "video_recording_framerate"),
    19: .standard(proto: "audio_recording_mode"),
    22: .standard(proto: "exposure_mode"),
    23: .standard(proto: "exposure_manual_shutter_speed"),
    24: .standard(proto: "exposure_manual_iso_sensitivity"),
    25: .standard(proto: "exposure_maximum_iso_sensitivity"),
    26: .standard(proto: "white_balance_mode"),
    27: .standard(proto: "white_balance_temperature"),
    28: .standard(proto: "ev_compensation"),
    29: .standard(proto: "image_style"),
    30: .standard(proto: "image_contrast"),
    31: .standard(proto: "image_saturation"),
    32: .standard(proto: "image_sharpness"),
    33: .standard(proto: "zoom_max_speed"),
    34: .standard(proto: "zoom_velocity_control_quality_mode"),
    35: .standard(proto: "auto_record_mode"),
    36: .standard(proto: "alignment_offset_pitch"),
    37: .standard(proto: "alignment_offset_roll"),
    38: .standard(proto: "alignment_offset_yaw"),
    39: .standard(proto: "photo_signature"),
    40: .standard(proto: "exposure_metering"),
    41: .standard(proto: "storage_policy"),
    42: .standard(proto: "video_recording_bitrate"),
  ]

  fileprivate class _StorageClass {
    var _selectedFields: Dictionary<UInt32,SwiftProtobuf.Google_Protobuf_Empty> = [:]
    var _cameraMode: Arsdk_Camera_CameraMode = .photo
    var _photoMode: Arsdk_Camera_PhotoMode = .single
    var _photoDynamicRange: Arsdk_Camera_DynamicRange = .standard
    var _photoResolution: Arsdk_Camera_PhotoResolution = .photoResolution48MegaPixels
    var _photoFormat: Arsdk_Camera_PhotoFormat = .fullFrame
    var _photoFileFormat: Arsdk_Camera_PhotoFileFormat = .jpeg
    var _photoBurstValue: Arsdk_Camera_BurstValue = .burstValue14Over4S
    var _photoBracketingPreset: Arsdk_Camera_BracketingPreset = .bracketingPreset1Ev
    var _photoTimeLapseInterval: Double = 0
    var _photoGpsLapseInterval: Double = 0
    var _photoStreamingMode: Arsdk_Camera_PhotoStreamingMode = .interrupt
    var _videoRecordingMode: Arsdk_Camera_VideoRecordingMode = .standard
    var _videoRecordingDynamicRange: Arsdk_Camera_DynamicRange = .standard
    var _videoRecordingCodec: Arsdk_Camera_VideoCodec = .h264
    var _videoRecordingResolution: Arsdk_Camera_VideoResolution = .reserved
    var _videoRecordingFramerate: Arsdk_Camera_Framerate = .framerate24
    var _audioRecordingMode: Arsdk_Camera_AudioRecordingMode = .mute
    var _exposureMode: Arsdk_Camera_ExposureMode = .automatic
    var _exposureManualShutterSpeed: Arsdk_Camera_ShutterSpeed = .shutterSpeed1Over10000
    var _exposureManualIsoSensitivity: Arsdk_Camera_IsoSensitivity = .isoSensitivity25
    var _exposureMaximumIsoSensitivity: Arsdk_Camera_IsoSensitivity = .isoSensitivity25
    var _whiteBalanceMode: Arsdk_Camera_WhiteBalanceMode = .custom
    var _whiteBalanceTemperature: Arsdk_Camera_WhiteBalanceTemperature = .whiteBalanceTemperature1500
    var _evCompensation: Arsdk_Camera_EvCompensation = .minus300
    var _imageStyle: Arsdk_Camera_ImageStyle = .custom
    var _imageContrast: Double = 0
    var _imageSaturation: Double = 0
    var _imageSharpness: Double = 0
    var _zoomMaxSpeed: Double = 0
    var _zoomVelocityControlQualityMode: Arsdk_Camera_ZoomVelocityControlQualityMode = .allowDegradation
    var _autoRecordMode: Arsdk_Camera_AutoRecordMode = .disabled
    var _alignmentOffsetPitch: Double = 0
    var _alignmentOffsetRoll: Double = 0
    var _alignmentOffsetYaw: Double = 0
    var _photoSignature: Arsdk_Camera_DigitalSignature = .none
    var _exposureMetering: Arsdk_Camera_ExposureMetering = .standard
    var _storagePolicy: Arsdk_Camera_StoragePolicy = .auto
    var _videoRecordingBitrate: UInt32 = 0

    static let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _selectedFields = source._selectedFields
      _cameraMode = source._cameraMode
      _photoMode = source._photoMode
      _photoDynamicRange = source._photoDynamicRange
      _photoResolution = source._photoResolution
      _photoFormat = source._photoFormat
      _photoFileFormat = source._photoFileFormat
      _photoBurstValue = source._photoBurstValue
      _photoBracketingPreset = source._photoBracketingPreset
      _photoTimeLapseInterval = source._photoTimeLapseInterval
      _photoGpsLapseInterval = source._photoGpsLapseInterval
      _photoStreamingMode = source._photoStreamingMode
      _videoRecordingMode = source._videoRecordingMode
      _videoRecordingDynamicRange = source._videoRecordingDynamicRange
      _videoRecordingCodec = source._videoRecordingCodec
      _videoRecordingResolution = source._videoRecordingResolution
      _videoRecordingFramerate = source._videoRecordingFramerate
      _audioRecordingMode = source._audioRecordingMode
      _exposureMode = source._exposureMode
      _exposureManualShutterSpeed = source._exposureManualShutterSpeed
      _exposureManualIsoSensitivity = source._exposureManualIsoSensitivity
      _exposureMaximumIsoSensitivity = source._exposureMaximumIsoSensitivity
      _whiteBalanceMode = source._whiteBalanceMode
      _whiteBalanceTemperature = source._whiteBalanceTemperature
      _evCompensation = source._evCompensation
      _imageStyle = source._imageStyle
      _imageContrast = source._imageContrast
      _imageSaturation = source._imageSaturation
      _imageSharpness = source._imageSharpness
      _zoomMaxSpeed = source._zoomMaxSpeed
      _zoomVelocityControlQualityMode = source._zoomVelocityControlQualityMode
      _autoRecordMode = source._autoRecordMode
      _alignmentOffsetPitch = source._alignmentOffsetPitch
      _alignmentOffsetRoll = source._alignmentOffsetRoll
      _alignmentOffsetYaw = source._alignmentOffsetYaw
      _photoSignature = source._photoSignature
      _exposureMetering = source._exposureMetering
      _storagePolicy = source._storagePolicy
      _videoRecordingBitrate = source._videoRecordingBitrate
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMessageMap<SwiftProtobuf.ProtobufUInt32,SwiftProtobuf.Google_Protobuf_Empty>.self, value: &_storage._selectedFields) }()
        case 2: try { try decoder.decodeSingularEnumField(value: &_storage._cameraMode) }()
        case 3: try { try decoder.decodeSingularEnumField(value: &_storage._photoMode) }()
        case 4: try { try decoder.decodeSingularEnumField(value: &_storage._photoDynamicRange) }()
        case 5: try { try decoder.decodeSingularEnumField(value: &_storage._photoResolution) }()
        case 6: try { try decoder.decodeSingularEnumField(value: &_storage._photoFormat) }()
        case 7: try { try decoder.decodeSingularEnumField(value: &_storage._photoFileFormat) }()
        case 8: try { try decoder.decodeSingularEnumField(value: &_storage._photoBurstValue) }()
        case 9: try { try decoder.decodeSingularEnumField(value: &_storage._photoBracketingPreset) }()
        case 10: try { try decoder.decodeSingularDoubleField(value: &_storage._photoTimeLapseInterval) }()
        case 11: try { try decoder.decodeSingularDoubleField(value: &_storage._photoGpsLapseInterval) }()
        case 12: try { try decoder.decodeSingularEnumField(value: &_storage._photoStreamingMode) }()
        case 13: try { try decoder.decodeSingularEnumField(value: &_storage._videoRecordingMode) }()
        case 14: try { try decoder.decodeSingularEnumField(value: &_storage._videoRecordingDynamicRange) }()
        case 15: try { try decoder.decodeSingularEnumField(value: &_storage._videoRecordingCodec) }()
        case 16: try { try decoder.decodeSingularEnumField(value: &_storage._videoRecordingResolution) }()
        case 17: try { try decoder.decodeSingularEnumField(value: &_storage._videoRecordingFramerate) }()
        case 19: try { try decoder.decodeSingularEnumField(value: &_storage._audioRecordingMode) }()
        case 22: try { try decoder.decodeSingularEnumField(value: &_storage._exposureMode) }()
        case 23: try { try decoder.decodeSingularEnumField(value: &_storage._exposureManualShutterSpeed) }()
        case 24: try { try decoder.decodeSingularEnumField(value: &_storage._exposureManualIsoSensitivity) }()
        case 25: try { try decoder.decodeSingularEnumField(value: &_storage._exposureMaximumIsoSensitivity) }()
        case 26: try { try decoder.decodeSingularEnumField(value: &_storage._whiteBalanceMode) }()
        case 27: try { try decoder.decodeSingularEnumField(value: &_storage._whiteBalanceTemperature) }()
        case 28: try { try decoder.decodeSingularEnumField(value: &_storage._evCompensation) }()
        case 29: try { try decoder.decodeSingularEnumField(value: &_storage._imageStyle) }()
        case 30: try { try decoder.decodeSingularDoubleField(value: &_storage._imageContrast) }()
        case 31: try { try decoder.decodeSingularDoubleField(value: &_storage._imageSaturation) }()
        case 32: try { try decoder.decodeSingularDoubleField(value: &_storage._imageSharpness) }()
        case 33: try { try decoder.decodeSingularDoubleField(value: &_storage._zoomMaxSpeed) }()
        case 34: try { try decoder.decodeSingularEnumField(value: &_storage._zoomVelocityControlQualityMode) }()
        case 35: try { try decoder.decodeSingularEnumField(value: &_storage._autoRecordMode) }()
        case 36: try { try decoder.decodeSingularDoubleField(value: &_storage._alignmentOffsetPitch) }()
        case 37: try { try decoder.decodeSingularDoubleField(value: &_storage._alignmentOffsetRoll) }()
        case 38: try { try decoder.decodeSingularDoubleField(value: &_storage._alignmentOffsetYaw) }()
        case 39: try { try decoder.decodeSingularEnumField(value: &_storage._photoSignature) }()
        case 40: try { try decoder.decodeSingularEnumField(value: &_storage._exposureMetering) }()
        case 41: try { try decoder.decodeSingularEnumField(value: &_storage._storagePolicy) }()
        case 42: try { try decoder.decodeSingularUInt32Field(value: &_storage._videoRecordingBitrate) }()
        default: break
        }
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      if !_storage._selectedFields.isEmpty {
        try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMessageMap<SwiftProtobuf.ProtobufUInt32,SwiftProtobuf.Google_Protobuf_Empty>.self, value: _storage._selectedFields, fieldNumber: 1)
      }
      if _storage._cameraMode != .photo {
        try visitor.visitSingularEnumField(value: _storage._cameraMode, fieldNumber: 2)
      }
      if _storage._photoMode != .single {
        try visitor.visitSingularEnumField(value: _storage._photoMode, fieldNumber: 3)
      }
      if _storage._photoDynamicRange != .standard {
        try visitor.visitSingularEnumField(value: _storage._photoDynamicRange, fieldNumber: 4)
      }
      if _storage._photoResolution != .photoResolution48MegaPixels {
        try visitor.visitSingularEnumField(value: _storage._photoResolution, fieldNumber: 5)
      }
      if _storage._photoFormat != .fullFrame {
        try visitor.visitSingularEnumField(value: _storage._photoFormat, fieldNumber: 6)
      }
      if _storage._photoFileFormat != .jpeg {
        try visitor.visitSingularEnumField(value: _storage._photoFileFormat, fieldNumber: 7)
      }
      if _storage._photoBurstValue != .burstValue14Over4S {
        try visitor.visitSingularEnumField(value: _storage._photoBurstValue, fieldNumber: 8)
      }
      if _storage._photoBracketingPreset != .bracketingPreset1Ev {
        try visitor.visitSingularEnumField(value: _storage._photoBracketingPreset, fieldNumber: 9)
      }
      if _storage._photoTimeLapseInterval != 0 {
        try visitor.visitSingularDoubleField(value: _storage._photoTimeLapseInterval, fieldNumber: 10)
      }
      if _storage._photoGpsLapseInterval != 0 {
        try visitor.visitSingularDoubleField(value: _storage._photoGpsLapseInterval, fieldNumber: 11)
      }
      if _storage._photoStreamingMode != .interrupt {
        try visitor.visitSingularEnumField(value: _storage._photoStreamingMode, fieldNumber: 12)
      }
      if _storage._videoRecordingMode != .standard {
        try visitor.visitSingularEnumField(value: _storage._videoRecordingMode, fieldNumber: 13)
      }
      if _storage._videoRecordingDynamicRange != .standard {
        try visitor.visitSingularEnumField(value: _storage._videoRecordingDynamicRange, fieldNumber: 14)
      }
      if _storage._videoRecordingCodec != .h264 {
        try visitor.visitSingularEnumField(value: _storage._videoRecordingCodec, fieldNumber: 15)
      }
      if _storage._videoRecordingResolution != .reserved {
        try visitor.visitSingularEnumField(value: _storage._videoRecordingResolution, fieldNumber: 16)
      }
      if _storage._videoRecordingFramerate != .framerate24 {
        try visitor.visitSingularEnumField(value: _storage._videoRecordingFramerate, fieldNumber: 17)
      }
      if _storage._audioRecordingMode != .mute {
        try visitor.visitSingularEnumField(value: _storage._audioRecordingMode, fieldNumber: 19)
      }
      if _storage._exposureMode != .automatic {
        try visitor.visitSingularEnumField(value: _storage._exposureMode, fieldNumber: 22)
      }
      if _storage._exposureManualShutterSpeed != .shutterSpeed1Over10000 {
        try visitor.visitSingularEnumField(value: _storage._exposureManualShutterSpeed, fieldNumber: 23)
      }
      if _storage._exposureManualIsoSensitivity != .isoSensitivity25 {
        try visitor.visitSingularEnumField(value: _storage._exposureManualIsoSensitivity, fieldNumber: 24)
      }
      if _storage._exposureMaximumIsoSensitivity != .isoSensitivity25 {
        try visitor.visitSingularEnumField(value: _storage._exposureMaximumIsoSensitivity, fieldNumber: 25)
      }
      if _storage._whiteBalanceMode != .custom {
        try visitor.visitSingularEnumField(value: _storage._whiteBalanceMode, fieldNumber: 26)
      }
      if _storage._whiteBalanceTemperature != .whiteBalanceTemperature1500 {
        try visitor.visitSingularEnumField(value: _storage._whiteBalanceTemperature, fieldNumber: 27)
      }
      if _storage._evCompensation != .minus300 {
        try visitor.visitSingularEnumField(value: _storage._evCompensation, fieldNumber: 28)
      }
      if _storage._imageStyle != .custom {
        try visitor.visitSingularEnumField(value: _storage._imageStyle, fieldNumber: 29)
      }
      if _storage._imageContrast != 0 {
        try visitor.visitSingularDoubleField(value: _storage._imageContrast, fieldNumber: 30)
      }
      if _storage._imageSaturation != 0 {
        try visitor.visitSingularDoubleField(value: _storage._imageSaturation, fieldNumber: 31)
      }
      if _storage._imageSharpness != 0 {
        try visitor.visitSingularDoubleField(value: _storage._imageSharpness, fieldNumber: 32)
      }
      if _storage._zoomMaxSpeed != 0 {
        try visitor.visitSingularDoubleField(value: _storage._zoomMaxSpeed, fieldNumber: 33)
      }
      if _storage._zoomVelocityControlQualityMode != .allowDegradation {
        try visitor.visitSingularEnumField(value: _storage._zoomVelocityControlQualityMode, fieldNumber: 34)
      }
      if _storage._autoRecordMode != .disabled {
        try visitor.visitSingularEnumField(value: _storage._autoRecordMode, fieldNumber: 35)
      }
      if _storage._alignmentOffsetPitch != 0 {
        try visitor.visitSingularDoubleField(value: _storage._alignmentOffsetPitch, fieldNumber: 36)
      }
      if _storage._alignmentOffsetRoll != 0 {
        try visitor.visitSingularDoubleField(value: _storage._alignmentOffsetRoll, fieldNumber: 37)
      }
      if _storage._alignmentOffsetYaw != 0 {
        try visitor.visitSingularDoubleField(value: _storage._alignmentOffsetYaw, fieldNumber: 38)
      }
      if _storage._photoSignature != .none {
        try visitor.visitSingularEnumField(value: _storage._photoSignature, fieldNumber: 39)
      }
      if _storage._exposureMetering != .standard {
        try visitor.visitSingularEnumField(value: _storage._exposureMetering, fieldNumber: 40)
      }
      if _storage._storagePolicy != .auto {
        try visitor.visitSingularEnumField(value: _storage._storagePolicy, fieldNumber: 41)
      }
      if _storage._videoRecordingBitrate != 0 {
        try visitor.visitSingularUInt32Field(value: _storage._videoRecordingBitrate, fieldNumber: 42)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Arsdk_Camera_Config, rhs: Arsdk_Camera_Config) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._selectedFields != rhs_storage._selectedFields {return false}
        if _storage._cameraMode != rhs_storage._cameraMode {return false}
        if _storage._photoMode != rhs_storage._photoMode {return false}
        if _storage._photoDynamicRange != rhs_storage._photoDynamicRange {return false}
        if _storage._photoResolution != rhs_storage._photoResolution {return false}
        if _storage._photoFormat != rhs_storage._photoFormat {return false}
        if _storage._photoFileFormat != rhs_storage._photoFileFormat {return false}
        if _storage._photoBurstValue != rhs_storage._photoBurstValue {return false}
        if _storage._photoBracketingPreset != rhs_storage._photoBracketingPreset {return false}
        if _storage._photoTimeLapseInterval != rhs_storage._photoTimeLapseInterval {return false}
        if _storage._photoGpsLapseInterval != rhs_storage._photoGpsLapseInterval {return false}
        if _storage._photoStreamingMode != rhs_storage._photoStreamingMode {return false}
        if _storage._videoRecordingMode != rhs_storage._videoRecordingMode {return false}
        if _storage._videoRecordingDynamicRange != rhs_storage._videoRecordingDynamicRange {return false}
        if _storage._videoRecordingCodec != rhs_storage._videoRecordingCodec {return false}
        if _storage._videoRecordingResolution != rhs_storage._videoRecordingResolution {return false}
        if _storage._videoRecordingFramerate != rhs_storage._videoRecordingFramerate {return false}
        if _storage._audioRecordingMode != rhs_storage._audioRecordingMode {return false}
        if _storage._exposureMode != rhs_storage._exposureMode {return false}
        if _storage._exposureManualShutterSpeed != rhs_storage._exposureManualShutterSpeed {return false}
        if _storage._exposureManualIsoSensitivity != rhs_storage._exposureManualIsoSensitivity {return false}
        if _storage._exposureMaximumIsoSensitivity != rhs_storage._exposureMaximumIsoSensitivity {return false}
        if _storage._whiteBalanceMode != rhs_storage._whiteBalanceMode {return false}
        if _storage._whiteBalanceTemperature != rhs_storage._whiteBalanceTemperature {return false}
        if _storage._evCompensation != rhs_storage._evCompensation {return false}
        if _storage._imageStyle != rhs_storage._imageStyle {return false}
        if _storage._imageContrast != rhs_storage._imageContrast {return false}
        if _storage._imageSaturation != rhs_storage._imageSaturation {return false}
        if _storage._imageSharpness != rhs_storage._imageSharpness {return false}
        if _storage._zoomMaxSpeed != rhs_storage._zoomMaxSpeed {return false}
        if _storage._zoomVelocityControlQualityMode != rhs_storage._zoomVelocityControlQualityMode {return false}
        if _storage._autoRecordMode != rhs_storage._autoRecordMode {return false}
        if _storage._alignmentOffsetPitch != rhs_storage._alignmentOffsetPitch {return false}
        if _storage._alignmentOffsetRoll != rhs_storage._alignmentOffsetRoll {return false}
        if _storage._alignmentOffsetYaw != rhs_storage._alignmentOffsetYaw {return false}
        if _storage._photoSignature != rhs_storage._photoSignature {return false}
        if _storage._exposureMetering != rhs_storage._exposureMetering {return false}
        if _storage._storagePolicy != rhs_storage._storagePolicy {return false}
        if _storage._videoRecordingBitrate != rhs_storage._videoRecordingBitrate {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Arsdk_Camera_DoubleRange: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".DoubleRange"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "min"),
    2: .same(proto: "max"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularDoubleField(value: &self.min) }()
      case 2: try { try decoder.decodeSingularDoubleField(value: &self.max) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.min != 0 {
      try visitor.visitSingularDoubleField(value: self.min, fieldNumber: 1)
    }
    if self.max != 0 {
      try visitor.visitSingularDoubleField(value: self.max, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Arsdk_Camera_DoubleRange, rhs: Arsdk_Camera_DoubleRange) -> Bool {
    if lhs.min != rhs.min {return false}
    if lhs.max != rhs.max {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Arsdk_Camera_ExposureRoi: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".ExposureRoi"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "center"),
    2: .same(proto: "width"),
    3: .same(proto: "height"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._center) }()
      case 2: try { try decoder.decodeSingularDoubleField(value: &self.width) }()
      case 3: try { try decoder.decodeSingularDoubleField(value: &self.height) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._center {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    if self.width != 0 {
      try visitor.visitSingularDoubleField(value: self.width, fieldNumber: 2)
    }
    if self.height != 0 {
      try visitor.visitSingularDoubleField(value: self.height, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Arsdk_Camera_ExposureRoi, rhs: Arsdk_Camera_ExposureRoi) -> Bool {
    if lhs._center != rhs._center {return false}
    if lhs.width != rhs.width {return false}
    if lhs.height != rhs.height {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Arsdk_Camera_ExposureRoi.Center: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Arsdk_Camera_ExposureRoi.protoMessageName + ".Center"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "x"),
    2: .same(proto: "y"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularDoubleField(value: &self.x) }()
      case 2: try { try decoder.decodeSingularDoubleField(value: &self.y) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.x != 0 {
      try visitor.visitSingularDoubleField(value: self.x, fieldNumber: 1)
    }
    if self.y != 0 {
      try visitor.visitSingularDoubleField(value: self.y, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Arsdk_Camera_ExposureRoi.Center, rhs: Arsdk_Camera_ExposureRoi.Center) -> Bool {
    if lhs.x != rhs.x {return false}
    if lhs.y != rhs.y {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Arsdk_Camera_MediaMetadata: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".MediaMetadata"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "selected_fields"),
    2: .same(proto: "copyright"),
    3: .standard(proto: "custom_id"),
    4: .standard(proto: "custom_title"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMessageMap<SwiftProtobuf.ProtobufUInt32,SwiftProtobuf.Google_Protobuf_Empty>.self, value: &self.selectedFields) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.copyright) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.customID) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.customTitle) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.selectedFields.isEmpty {
      try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMessageMap<SwiftProtobuf.ProtobufUInt32,SwiftProtobuf.Google_Protobuf_Empty>.self, value: self.selectedFields, fieldNumber: 1)
    }
    if !self.copyright.isEmpty {
      try visitor.visitSingularStringField(value: self.copyright, fieldNumber: 2)
    }
    if !self.customID.isEmpty {
      try visitor.visitSingularStringField(value: self.customID, fieldNumber: 3)
    }
    if !self.customTitle.isEmpty {
      try visitor.visitSingularStringField(value: self.customTitle, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Arsdk_Camera_MediaMetadata, rhs: Arsdk_Camera_MediaMetadata) -> Bool {
    if lhs.selectedFields != rhs.selectedFields {return false}
    if lhs.copyright != rhs.copyright {return false}
    if lhs.customID != rhs.customID {return false}
    if lhs.customTitle != rhs.customTitle {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}
